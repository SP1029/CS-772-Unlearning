{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "242ea38e",
   "metadata": {
    "id": "K7GwEjnhDPqh",
    "papermill": {
     "duration": 0.005788,
     "end_time": "2024-04-21T16:49:24.887750",
     "exception": false,
     "start_time": "2024-04-21T16:49:24.881962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a21e2ce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T16:49:24.900048Z",
     "iopub.status.busy": "2024-04-21T16:49:24.899796Z",
     "iopub.status.idle": "2024-04-21T16:49:28.606993Z",
     "shell.execute_reply": "2024-04-21T16:49:28.606213Z"
    },
    "id": "LJrmlufaDRtm",
    "papermill": {
     "duration": 3.716059,
     "end_time": "2024-04-21T16:49:28.609313",
     "exception": false,
     "start_time": "2024-04-21T16:49:24.893254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ConvStandard(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=None, output_padding=0, w_sig =\\\n",
    "                 np.sqrt(1.0)):\n",
    "        super(ConvStandard, self).__init__(in_channels, out_channels,kernel_size)\n",
    "        self.in_channels=in_channels\n",
    "        self.out_channels=out_channels\n",
    "        self.kernel_size=kernel_size\n",
    "        self.stride=stride\n",
    "        self.padding=padding\n",
    "        self.w_sig = w_sig\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.normal_(self.weight, mean=0, std=self.w_sig/(self.in_channels*np.prod(self.kernel_size)))\n",
    "        if self.bias is not None:\n",
    "            torch.nn.init.normal_(self.bias, mean=0, std=0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.conv2d(input,self.weight,self.bias,self.stride,self.padding)\n",
    "\n",
    "class Conv(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=None, output_padding=0,\n",
    "                 activation_fn=nn.ReLU, batch_norm=True, transpose=False):\n",
    "        if padding is None:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        model = []\n",
    "        if not transpose:\n",
    "#             model += [ConvStandard(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "#                                 )]\n",
    "            model += [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                bias=not batch_norm)]\n",
    "        else:\n",
    "            model += [nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding,\n",
    "                                         output_padding=output_padding, bias=not batch_norm)]\n",
    "        if batch_norm:\n",
    "            model += [nn.BatchNorm2d(out_channels, affine=True)]\n",
    "        model += [activation_fn()]\n",
    "        super(Conv, self).__init__(*model)\n",
    "\n",
    "class AllCNN(nn.Module):\n",
    "    def __init__(self, filters_percentage=1., n_channels=3, num_classes=10, dropout=False, batch_norm=True):\n",
    "        super(AllCNN, self).__init__()\n",
    "        n_filter1 = int(96 * filters_percentage)\n",
    "        n_filter2 = int(192 * filters_percentage)\n",
    "\n",
    "        self.conv1 = Conv(n_channels, n_filter1, kernel_size=3, batch_norm=batch_norm)\n",
    "        self.conv2 = Conv(n_filter1, n_filter1, kernel_size=3, batch_norm=batch_norm)\n",
    "        self.conv3 = Conv(n_filter1, n_filter2, kernel_size=3, stride=2, padding=1, batch_norm=batch_norm)\n",
    "\n",
    "        self.dropout1 = self.features = nn.Sequential(nn.Dropout(inplace=True) if dropout else Identity())\n",
    "\n",
    "        self.conv4 = Conv(n_filter2, n_filter2, kernel_size=3, stride=1, batch_norm=batch_norm)\n",
    "        self.conv5 = Conv(n_filter2, n_filter2, kernel_size=3, stride=1, batch_norm=batch_norm)\n",
    "        self.conv6 = Conv(n_filter2, n_filter2, kernel_size=3, stride=2, padding=1, batch_norm=batch_norm)\n",
    "\n",
    "        self.dropout2 = self.features = nn.Sequential(nn.Dropout(inplace=True) if dropout else Identity())\n",
    "\n",
    "        self.conv7 = Conv(n_filter2, n_filter2, kernel_size=3, stride=1, batch_norm=batch_norm)\n",
    "        self.conv8 = Conv(n_filter2, n_filter2, kernel_size=1, stride=1, batch_norm=batch_norm)\n",
    "        if n_channels == 3:\n",
    "            self.pool = nn.AvgPool2d(8)\n",
    "        elif n_channels == 1:\n",
    "            self.pool = nn.AvgPool2d(7)\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_filter2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        actv1 = out\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        actv2 = out\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        actv3 = out\n",
    "\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        out = self.conv4(out)\n",
    "        actv4 = out\n",
    "\n",
    "        out = self.conv5(out)\n",
    "        actv5 = out\n",
    "\n",
    "        out = self.conv6(out)\n",
    "        actv6 = out\n",
    "\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        out = self.conv7(out)\n",
    "        actv7 = out\n",
    "\n",
    "        out = self.conv8(out)\n",
    "        actv8 = out\n",
    "\n",
    "        out = self.pool(out)\n",
    "\n",
    "        out = self.flatten(out)\n",
    "\n",
    "        out = self.classifier(out)\n",
    "\n",
    "        return out, actv1, actv2, actv3, actv4, actv5, actv6, actv7, actv8\n",
    "\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(View, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.view(self.size)\n",
    "\n",
    "\n",
    "class LeNet32(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(LeNet32, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            View((-1, 16*5*5)),\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, n_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x, true_labels=None):\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if idx == 0:\n",
    "                activation1 = x\n",
    "            if idx == 3:\n",
    "                activation2 = x\n",
    "\n",
    "        return x, activation1, activation2\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual block as defined by He et al.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_res1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                                   padding=padding, stride=stride, bias=False)\n",
    "        self.conv_res1_bn = nn.BatchNorm2d(num_features=out_channels, momentum=0.9)\n",
    "        self.conv_res2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                                   padding=padding, bias=False)\n",
    "        self.conv_res2_bn = nn.BatchNorm2d(num_features=out_channels, momentum=0.9)\n",
    "\n",
    "        if stride != 1:\n",
    "            # in case stride is not set to 1, we need to downsample the residual so that\n",
    "            # the dimensions are the same when we add them together\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(num_features=out_channels, momentum=0.9)\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.relu(self.conv_res1_bn(self.conv_res1(x)))\n",
    "        out = self.conv_res2_bn(self.conv_res2(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(residual)\n",
    "\n",
    "        out = self.relu(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    \"\"\"\n",
    "    A Residual network.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=64, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=128, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            ResidualBlock(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=256, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=256, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            ResidualBlock(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(in_features=1024, out_features=10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for idx, layer in enumerate(self.conv):\n",
    "            x = layer(x)\n",
    "            if idx == 0:\n",
    "                activation1 = x\n",
    "            if idx == 3:\n",
    "                activation2 = x\n",
    "            if idx == 8:\n",
    "                activation3 = x\n",
    "            if idx == 12:\n",
    "                activation4 = x\n",
    "\n",
    "        x = x.view(-1, x.shape[1] * x.shape[2] * x.shape[3])\n",
    "        x = self.fc(x)\n",
    "        return x, activation1, activation2, activation3, activation4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4650915",
   "metadata": {
    "id": "dQOLxw4aDU6g",
    "papermill": {
     "duration": 0.005168,
     "end_time": "2024-04-21T16:49:28.620107",
     "exception": false,
     "start_time": "2024-04-21T16:49:28.614939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "723ad9b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T16:49:28.631953Z",
     "iopub.status.busy": "2024-04-21T16:49:28.631579Z",
     "iopub.status.idle": "2024-04-21T16:49:28.656668Z",
     "shell.execute_reply": "2024-04-21T16:49:28.655692Z"
    },
    "id": "wkiAg4CNDYFg",
    "papermill": {
     "duration": 0.033212,
     "end_time": "2024-04-21T16:49:28.658528",
     "exception": false,
     "start_time": "2024-04-21T16:49:28.625316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def accuracy_class(outputs, labels, myclass):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "#     print(preds)\n",
    "#     print(labels == myclass, '--', preds == labels, '--', torch.logical_and(preds == labels, labels == myclass))\n",
    "#     print(\"acc_class: \",myclass, '--', torch.tensor(torch.sum(torch.logical_and(preds == labels, labels == myclass)).item() / torch.sum((labels==myclass)).item()))\n",
    "    if torch.sum((labels==myclass)).item()==0:\n",
    "        return torch.tensor(0.0)\n",
    "    else:\n",
    "        return torch.tensor(torch.sum(torch.logical_and(preds == labels, labels == myclass)).item() / torch.sum((labels==myclass)).item())\n",
    "\n",
    "def training_step(model, batch, device):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    out, *_ = model(images)                  # Generate predictions\n",
    "#     print(labels)\n",
    "    loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "    return loss\n",
    "\n",
    "def validation_step(model, batch, device):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    out, *_ = model(images)                    # Generate predictions\n",
    "    loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "    acc = accuracy(out, labels)           # Calculate accuracy\n",
    "    acc_classwise=[]\n",
    "    for i in range(10):\n",
    "        acc_classwise.append(accuracy_class(out, labels, i))\n",
    "    fin_ans={'Loss': loss.detach(), 'Acc': acc}\n",
    "    for i in range(10):\n",
    "        fin_ans['Acc'+str(i)]=acc_classwise[i]\n",
    "#     print(\"fin_ans: \", fin_ans)\n",
    "    return fin_ans\n",
    "\n",
    "def validation_epoch_end(model, outputs):\n",
    "    batch_losses = [x['Loss'] for x in outputs]\n",
    "    epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "    batch_accs = [x['Acc'] for x in outputs]\n",
    "    epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "    batch_accs_list=[]\n",
    "    epoch_acc_list=[]\n",
    "    for i in range(10):\n",
    "        batch_accs_list.append( [x['Acc'+str(i)] for x in outputs])\n",
    "        epoch_acc_list.append( torch.stack(batch_accs_list[i]).mean())      # Combine accuracies\n",
    "    fin_ans={'Loss': epoch_loss.item(), 'Acc': epoch_acc.item()}\n",
    "    for i in range(10):\n",
    "        fin_ans['Acc'+str(i)]=epoch_acc_list[i].item()\n",
    "    return fin_ans\n",
    "\n",
    "def epoch_end(model, epoch, result):\n",
    "    print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "        epoch, result['lrs'][-1], result['train_loss'], result['Loss'], result['Acc']))\n",
    "    for i in range(10):\n",
    "        print(\"val_acc \", i, result['Acc'+str(i)])\n",
    "def epoch_end_without_lrs(model, epoch, result):\n",
    "    print(\"Epoch [{}],   val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "        epoch,  result['Loss'], result['Acc']))\n",
    "    for i in range(10):\n",
    "        print(\"val_acc \", i, result['Acc'+str(i)])\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    outputs = [validation_step(model, batch, device) for batch in val_loader]\n",
    "    return validation_epoch_end(model, outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD, device='cuda'):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = training_step(model, batch, device)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            if grad_clip:\n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            lrs.append(get_lr(optimizer))\n",
    "\n",
    "\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader, device)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        epoch_end(model, epoch, result)\n",
    "        history.append(result)\n",
    "        sched.step(result['Loss'])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b81c882",
   "metadata": {
    "papermill": {
     "duration": 0.005134,
     "end_time": "2024-04-21T16:49:28.668956",
     "exception": false,
     "start_time": "2024-04-21T16:49:28.663822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Self Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634e8aa0",
   "metadata": {
    "id": "tvm7S3SVDhpf",
    "papermill": {
     "duration": 0.005082,
     "end_time": "2024-04-21T16:49:28.679387",
     "exception": false,
     "start_time": "2024-04-21T16:49:28.674305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Unlearn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70021fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T16:49:28.691533Z",
     "iopub.status.busy": "2024-04-21T16:49:28.691256Z",
     "iopub.status.idle": "2024-04-21T16:49:28.713016Z",
     "shell.execute_reply": "2024-04-21T16:49:28.712204Z"
    },
    "id": "-C3moEJZDpXn",
    "papermill": {
     "duration": 0.030213,
     "end_time": "2024-04-21T16:49:28.714884",
     "exception": false,
     "start_time": "2024-04-21T16:49:28.684671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def attention(x):\n",
    "        \"\"\"\n",
    "        Taken from https://github.com/szagoruyko/attention-transfer\n",
    "        :param x = activations\n",
    "        \"\"\"\n",
    "        return F.normalize(x.pow(2).mean(1).view(x.size(0), -1))\n",
    "\n",
    "\n",
    "def attention_diff(x, y):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/szagoruyko/attention-transfer\n",
    "    :param x = activations\n",
    "    :param y = activations\n",
    "    \"\"\"\n",
    "    return (attention(x) - attention(y)).pow(2).mean()\n",
    "\n",
    "\n",
    "def divergence(student_logits, teacher_logits, KL_temperature):\n",
    "    divergence = F.kl_div(F.log_softmax(student_logits / KL_temperature, dim=1), F.softmax(teacher_logits / KL_temperature, dim=1))  # forward KL\n",
    "\n",
    "    return divergence\n",
    "\n",
    "\n",
    "def KT_loss_generator(student_logits, teacher_logits, KL_temperature):\n",
    "\n",
    "    divergence_loss = divergence(student_logits, teacher_logits, KL_temperature)\n",
    "    total_loss = - divergence_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def KT_loss_student(student_logits, student_activations, teacher_logits, teacher_activations, KL_temperature = 1, AT_beta = 250):\n",
    "\n",
    "    divergence_loss = divergence(student_logits, teacher_logits, KL_temperature)\n",
    "    if AT_beta > 0:\n",
    "        at_loss = 0\n",
    "        for i in range(len(student_activations)):\n",
    "            at_loss = at_loss + AT_beta * attention_diff(student_activations[i], teacher_activations[i])\n",
    "    else:\n",
    "        at_loss = 0        \n",
    "        \n",
    "    # Masking Student Attention\n",
    "    at_loss = 0\n",
    "    total_loss = divergence_loss + at_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim, num_channels = 3):\n",
    "        super(Generator, self).__init__()\n",
    "        prefinal_layer = None\n",
    "        final_layer = None\n",
    "        if num_channels == 3:\n",
    "            prefinal_layer = nn.Conv2d(64, 3, 3, stride=1, padding=1)\n",
    "            final_layer = nn.BatchNorm2d(3, affine=True)\n",
    "        elif num_channels == 1:\n",
    "            prefinal_layer = nn.Conv2d(64, 1, 7, stride=1, padding=1)\n",
    "            final_layer = nn.BatchNorm2d(1, affine=True)\n",
    "        else:\n",
    "            print(f\"Generator Not Supported for {num_channels} channels\")\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(z_dim, 128 * 8**2),\n",
    "            View((-1, 128, 8, 8)),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            prefinal_layer,\n",
    "            final_layer\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.layers(z)\n",
    "\n",
    "    def print_shape(self, x):\n",
    "        \"\"\"\n",
    "        For debugging purposes\n",
    "        \"\"\"\n",
    "        act = x\n",
    "        for layer in self.layers:\n",
    "            act = layer(act)\n",
    "            print('\\n', layer, '---->', act.shape)\n",
    "\n",
    "\n",
    "class LearnableLoader(nn.Module):\n",
    "    def __init__(self, n_repeat_batch, num_channels = 3,device='cuda'):\n",
    "        \"\"\"\n",
    "        Infinite loader, which contains a learnable generator.\n",
    "        \"\"\"\n",
    "\n",
    "        super(LearnableLoader, self).__init__()\n",
    "        self.batch_size = 256\n",
    "        self.n_repeat_batch = n_repeat_batch\n",
    "        self.z_dim = 128\n",
    "        self.generator = Generator(self.z_dim, num_channels=num_channels).to(device=device)\n",
    "        self.device = device\n",
    "\n",
    "        self._running_repeat_batch_idx = 0\n",
    "        self.z = torch.randn((self.batch_size, self.z_dim)).to(device=self.device)\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._running_repeat_batch_idx == self.n_repeat_batch:\n",
    "            self.z = torch.randn((self.batch_size, self.z_dim)).to(device=self.device)\n",
    "            self._running_repeat_batch_idx = 0\n",
    "\n",
    "        images = self.generator(self.z)\n",
    "        self._running_repeat_batch_idx += 1\n",
    "        return images\n",
    "\n",
    "    def samples(self, n, grid=True):\n",
    "        \"\"\"\n",
    "        :return: if grid returns single grid image, else\n",
    "        returns n images.\n",
    "        \"\"\"\n",
    "        self.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn((n, self.z_dim)).to(device=self.device)\n",
    "            images = visualize(self.generator(z), dataset=self.dataset).cpu()\n",
    "            if grid:\n",
    "                images = make_grid(images, nrow=round(math.sqrt(n)), normalize=True)\n",
    "\n",
    "        self.generator.train()\n",
    "        return images\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b886c",
   "metadata": {
    "id": "yywXC9m8Dwsn",
    "papermill": {
     "duration": 0.005041,
     "end_time": "2024-04-21T16:49:28.725232",
     "exception": false,
     "start_time": "2024-04-21T16:49:28.720191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d9f3bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T16:49:28.737048Z",
     "iopub.status.busy": "2024-04-21T16:49:28.736801Z",
     "iopub.status.idle": "2024-04-21T16:49:32.138662Z",
     "shell.execute_reply": "2024-04-21T16:49:32.137817Z"
    },
    "id": "_shdf4zqDx7E",
    "outputId": "f3b0ef52-6612-40ca-ecaa-9ccb12adb386",
    "papermill": {
     "duration": 3.410547,
     "end_time": "2024-04-21T16:49:32.140977",
     "exception": false,
     "start_time": "2024-04-21T16:49:28.730430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ecac0407690>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necessary Imports\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c66a73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T16:49:32.153668Z",
     "iopub.status.busy": "2024-04-21T16:49:32.153271Z",
     "iopub.status.idle": "2024-04-21T16:49:32.287889Z",
     "shell.execute_reply": "2024-04-21T16:49:32.286909Z"
    },
    "papermill": {
     "duration": 0.142984,
     "end_time": "2024-04-21T16:49:32.289891",
     "exception": false,
     "start_time": "2024-04-21T16:49:32.146907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torchvision\n",
    "import torchvision.transforms as tt\n",
    "import tarfile\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        image = tt.functional.rgb_to_grayscale(image)\n",
    "        image = image / 255        \n",
    "        return image, label\n",
    "    \n",
    "def mnist(root = './'):\n",
    "    transform = tt.Compose([\n",
    "        tt.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_ds = torchvision.datasets.MNIST(root='./', train=True, download=True, transform=transform)\n",
    "    valid_ds = torchvision.datasets.MNIST(root='./', train=False, download=True, transform=transform)\n",
    "\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f29aa9d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T16:49:32.302380Z",
     "iopub.status.busy": "2024-04-21T16:49:32.302094Z",
     "iopub.status.idle": "2024-04-21T16:49:33.271913Z",
     "shell.execute_reply": "2024-04-21T16:49:33.271074Z"
    },
    "papermill": {
     "duration": 0.978432,
     "end_time": "2024-04-21T16:49:33.274112",
     "exception": false,
     "start_time": "2024-04-21T16:49:32.295680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 136604932.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 48786022.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 43569335.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 11496999.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_ds= CustomImageDataset(\"/kaggle/input/60000-labels/retain_labels.csv\", \"/kaggle/input/60000/final_images/test\")\n",
    "_, valid_ds = mnist()\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5945bcb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T16:49:33.289726Z",
     "iopub.status.busy": "2024-04-21T16:49:33.289401Z",
     "iopub.status.idle": "2024-04-21T16:49:33.293394Z",
     "shell.execute_reply": "2024-04-21T16:49:33.292551Z"
    },
    "id": "0I3jnEXID5LW",
    "papermill": {
     "duration": 0.014028,
     "end_time": "2024-04-21T16:49:33.295417",
     "exception": false,
     "start_time": "2024-04-21T16:49:33.281389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc447c63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T16:49:33.310531Z",
     "iopub.status.busy": "2024-04-21T16:49:33.310237Z",
     "iopub.status.idle": "2024-04-21T16:49:33.558680Z",
     "shell.execute_reply": "2024-04-21T16:49:33.557874Z"
    },
    "id": "sLQnr5ivD67r",
    "papermill": {
     "duration": 0.258489,
     "end_time": "2024-04-21T16:49:33.560907",
     "exception": false,
     "start_time": "2024-04-21T16:49:33.302418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AllCNN(n_channels = 1).to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d904e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T16:49:33.577405Z",
     "iopub.status.busy": "2024-04-21T16:49:33.577091Z",
     "iopub.status.idle": "2024-04-21T16:49:33.581728Z",
     "shell.execute_reply": "2024-04-21T16:49:33.580845Z"
    },
    "id": "-IDTJ9JAD8Ao",
    "papermill": {
     "duration": 0.014988,
     "end_time": "2024-04-21T16:49:33.583680",
     "exception": false,
     "start_time": "2024-04-21T16:49:33.568692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "max_lr = 0.001\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28c55b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T16:49:33.599640Z",
     "iopub.status.busy": "2024-04-21T16:49:33.599337Z",
     "iopub.status.idle": "2024-04-21T17:50:33.422366Z",
     "shell.execute_reply": "2024-04-21T17:50:33.421395Z"
    },
    "id": "rjIm1PW6D9jV",
    "outputId": "285fee58-daff-44d3-b8a1-a303be48637b",
    "papermill": {
     "duration": 3659.844606,
     "end_time": "2024-04-21T17:50:33.435333",
     "exception": false,
     "start_time": "2024-04-21T16:49:33.590727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00100, train_loss: 0.1495, val_loss: 3.2067, val_acc: 0.2965\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.0025574713945388794\n",
      "val_acc  2 0.06496509164571762\n",
      "val_acc  3 0.46517816185951233\n",
      "val_acc  4 0.9320520162582397\n",
      "val_acc  5 1.0\n",
      "val_acc  6 0.12192980945110321\n",
      "val_acc  7 0.3132651448249817\n",
      "val_acc  8 0.0718574970960617\n",
      "val_acc  9 0.047280944883823395\n",
      "Epoch [1], last_lr: 0.00100, train_loss: 0.0069, val_loss: 2.7949, val_acc: 0.4995\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.20936384797096252\n",
      "val_acc  2 0.6921340227127075\n",
      "val_acc  3 0.0714319497346878\n",
      "val_acc  4 0.8485248684883118\n",
      "val_acc  5 0.8378133773803711\n",
      "val_acc  6 0.0028873090632259846\n",
      "val_acc  7 0.8782708048820496\n",
      "val_acc  8 0.8130711317062378\n",
      "val_acc  9 0.670924186706543\n",
      "Epoch [2], last_lr: 0.00100, train_loss: 0.0035, val_loss: 2.5824, val_acc: 0.4551\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.18240484595298767\n",
      "val_acc  2 0.16234204173088074\n",
      "val_acc  3 0.6025605201721191\n",
      "val_acc  4 0.2920435965061188\n",
      "val_acc  5 0.958418071269989\n",
      "val_acc  6 0.30544644594192505\n",
      "val_acc  7 0.8442126512527466\n",
      "val_acc  8 0.2778840661048889\n",
      "val_acc  9 0.9333839416503906\n",
      "Epoch [3], last_lr: 0.00100, train_loss: 0.0039, val_loss: 1.3756, val_acc: 0.6702\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.7272263169288635\n",
      "val_acc  2 0.626560389995575\n",
      "val_acc  3 0.9630013704299927\n",
      "val_acc  4 0.8223745226860046\n",
      "val_acc  5 0.9840113520622253\n",
      "val_acc  6 0.5124604105949402\n",
      "val_acc  7 0.8966576457023621\n",
      "val_acc  8 0.6320139169692993\n",
      "val_acc  9 0.552512526512146\n",
      "Epoch [4], last_lr: 0.00100, train_loss: 0.0019, val_loss: 8.9954, val_acc: 0.2698\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.0\n",
      "val_acc  2 0.0\n",
      "val_acc  3 0.005395299289375544\n",
      "val_acc  4 0.025130977854132652\n",
      "val_acc  5 0.9976190328598022\n",
      "val_acc  6 0.5065577030181885\n",
      "val_acc  7 0.0\n",
      "val_acc  8 0.8588541746139526\n",
      "val_acc  9 0.4260571599006653\n",
      "Epoch [5], last_lr: 0.00100, train_loss: 0.0045, val_loss: 1.0720, val_acc: 0.7546\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.8933383822441101\n",
      "val_acc  2 0.7798945307731628\n",
      "val_acc  3 0.9044920206069946\n",
      "val_acc  4 0.8302132487297058\n",
      "val_acc  5 0.9847292900085449\n",
      "val_acc  6 0.7472918629646301\n",
      "val_acc  7 0.8769296407699585\n",
      "val_acc  8 0.7320854663848877\n",
      "val_acc  9 0.7681804895401001\n",
      "Epoch [6], last_lr: 0.00100, train_loss: 0.0049, val_loss: 5.8017, val_acc: 0.3320\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.8743151426315308\n",
      "val_acc  2 0.26998430490493774\n",
      "val_acc  3 0.4028066098690033\n",
      "val_acc  4 0.8245027661323547\n",
      "val_acc  5 0.22547820210456848\n",
      "val_acc  6 0.005904349032789469\n",
      "val_acc  7 0.528410792350769\n",
      "val_acc  8 0.05784039944410324\n",
      "val_acc  9 0.010004721581935883\n",
      "Epoch [7], last_lr: 0.00100, train_loss: 0.0005, val_loss: 1.2933, val_acc: 0.7290\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.8374348878860474\n",
      "val_acc  2 0.7706930041313171\n",
      "val_acc  3 0.9279583096504211\n",
      "val_acc  4 0.7731001377105713\n",
      "val_acc  5 0.9546538591384888\n",
      "val_acc  6 0.5916327238082886\n",
      "val_acc  7 0.7392579913139343\n",
      "val_acc  8 0.8432865142822266\n",
      "val_acc  9 0.7548261880874634\n",
      "Epoch [8], last_lr: 0.00100, train_loss: 0.0003, val_loss: 1.0850, val_acc: 0.7509\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.8591673970222473\n",
      "val_acc  2 0.8525069952011108\n",
      "val_acc  3 0.9470078349113464\n",
      "val_acc  4 0.8219515085220337\n",
      "val_acc  5 0.9768320918083191\n",
      "val_acc  6 0.6037172675132751\n",
      "val_acc  7 0.7987813353538513\n",
      "val_acc  8 0.9046937227249146\n",
      "val_acc  9 0.7277197241783142\n",
      "Epoch [9], last_lr: 0.00100, train_loss: 0.0003, val_loss: 1.0147, val_acc: 0.7429\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.860336422920227\n",
      "val_acc  2 0.797895073890686\n",
      "val_acc  3 0.9751087427139282\n",
      "val_acc  4 0.874424934387207\n",
      "val_acc  5 0.9863570332527161\n",
      "val_acc  6 0.5427623987197876\n",
      "val_acc  7 0.8391340970993042\n",
      "val_acc  8 0.8867412805557251\n",
      "val_acc  9 0.5450051426887512\n",
      "Epoch [10], last_lr: 0.00100, train_loss: 0.0003, val_loss: 3.0777, val_acc: 0.4503\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.8995517492294312\n",
      "val_acc  2 0.29755693674087524\n",
      "val_acc  3 0.2803986370563507\n",
      "val_acc  4 0.5939775705337524\n",
      "val_acc  5 0.2537594735622406\n",
      "val_acc  6 0.510068953037262\n",
      "val_acc  7 0.29919347167015076\n",
      "val_acc  8 0.8063172101974487\n",
      "val_acc  9 0.4520992636680603\n",
      "Epoch [11], last_lr: 0.00100, train_loss: 0.0390, val_loss: 3.0740, val_acc: 0.5127\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.24819770455360413\n",
      "val_acc  2 0.5763353705406189\n",
      "val_acc  3 0.39528849720954895\n",
      "val_acc  4 0.9091224670410156\n",
      "val_acc  5 0.8686076998710632\n",
      "val_acc  6 0.3727339804172516\n",
      "val_acc  7 0.9096730351448059\n",
      "val_acc  8 0.5399458408355713\n",
      "val_acc  9 0.34580641984939575\n",
      "Epoch [12], last_lr: 0.00100, train_loss: 0.0018, val_loss: 3.3135, val_acc: 0.5287\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.788834810256958\n",
      "val_acc  2 0.40411481261253357\n",
      "val_acc  3 0.8195760846138\n",
      "val_acc  4 0.33336111903190613\n",
      "val_acc  5 0.9333125352859497\n",
      "val_acc  6 0.49753275513648987\n",
      "val_acc  7 0.30773577094078064\n",
      "val_acc  8 0.42749905586242676\n",
      "val_acc  9 0.7338305115699768\n",
      "Epoch [13], last_lr: 0.00100, train_loss: 0.0020, val_loss: 2.3343, val_acc: 0.6104\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.6845199465751648\n",
      "val_acc  2 0.7940366864204407\n",
      "val_acc  3 0.9346474409103394\n",
      "val_acc  4 0.7019119262695312\n",
      "val_acc  5 0.9129160046577454\n",
      "val_acc  6 0.3210415244102478\n",
      "val_acc  7 0.8578993678092957\n",
      "val_acc  8 0.5643758773803711\n",
      "val_acc  9 0.27727848291397095\n",
      "Epoch 00014: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [14], last_lr: 0.00050, train_loss: 0.0006, val_loss: 1.9135, val_acc: 0.6435\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.6640769839286804\n",
      "val_acc  2 0.7861698865890503\n",
      "val_acc  3 0.9786279797554016\n",
      "val_acc  4 0.7327037453651428\n",
      "val_acc  5 0.9023967981338501\n",
      "val_acc  6 0.4882067143917084\n",
      "val_acc  7 0.80064857006073\n",
      "val_acc  8 0.5503661036491394\n",
      "val_acc  9 0.48481446504592896\n",
      "Epoch [15], last_lr: 0.00050, train_loss: 0.0005, val_loss: 1.8043, val_acc: 0.6437\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.6010691523551941\n",
      "val_acc  2 0.8179394006729126\n",
      "val_acc  3 0.9633808135986328\n",
      "val_acc  4 0.6883836984634399\n",
      "val_acc  5 0.9207528829574585\n",
      "val_acc  6 0.4337138533592224\n",
      "val_acc  7 0.8639688491821289\n",
      "val_acc  8 0.6823693513870239\n",
      "val_acc  9 0.42759543657302856\n",
      "Epoch [16], last_lr: 0.00050, train_loss: 0.0004, val_loss: 1.8111, val_acc: 0.6348\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.6783574819564819\n",
      "val_acc  2 0.6701570153236389\n",
      "val_acc  3 0.9668877720832825\n",
      "val_acc  4 0.6371630430221558\n",
      "val_acc  5 0.8868149518966675\n",
      "val_acc  6 0.4564284384250641\n",
      "val_acc  7 0.8317191004753113\n",
      "val_acc  8 0.5889427065849304\n",
      "val_acc  9 0.6353828310966492\n",
      "Epoch [17], last_lr: 0.00050, train_loss: 0.0004, val_loss: 1.5444, val_acc: 0.6632\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.6038927435874939\n",
      "val_acc  2 0.8021000027656555\n",
      "val_acc  3 0.9640692472457886\n",
      "val_acc  4 0.7439568042755127\n",
      "val_acc  5 0.873562216758728\n",
      "val_acc  6 0.48309198021888733\n",
      "val_acc  7 0.7737954258918762\n",
      "val_acc  8 0.736170768737793\n",
      "val_acc  9 0.6046940088272095\n",
      "Epoch 00018: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [18], last_lr: 0.00025, train_loss: 0.0004, val_loss: 1.5140, val_acc: 0.6612\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5787458419799805\n",
      "val_acc  2 0.6993845701217651\n",
      "val_acc  3 0.9852190017700195\n",
      "val_acc  4 0.7650430202484131\n",
      "val_acc  5 0.9472352862358093\n",
      "val_acc  6 0.5675268173217773\n",
      "val_acc  7 0.8367993235588074\n",
      "val_acc  8 0.6969865560531616\n",
      "val_acc  9 0.5305865406990051\n",
      "Epoch [19], last_lr: 0.00025, train_loss: 0.0004, val_loss: 1.4815, val_acc: 0.6609\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5539825558662415\n",
      "val_acc  2 0.7534159421920776\n",
      "val_acc  3 0.9674881100654602\n",
      "val_acc  4 0.7250643968582153\n",
      "val_acc  5 0.901048481464386\n",
      "val_acc  6 0.5306932926177979\n",
      "val_acc  7 0.8288360834121704\n",
      "val_acc  8 0.8527997732162476\n",
      "val_acc  9 0.49607738852500916\n",
      "Epoch [20], last_lr: 0.00025, train_loss: 0.0004, val_loss: 1.3371, val_acc: 0.6896\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5742409825325012\n",
      "val_acc  2 0.83485347032547\n",
      "val_acc  3 0.9462584257125854\n",
      "val_acc  4 0.7684707641601562\n",
      "val_acc  5 0.9303210377693176\n",
      "val_acc  6 0.5305172204971313\n",
      "val_acc  7 0.8163938522338867\n",
      "val_acc  8 0.8725651502609253\n",
      "val_acc  9 0.6008686423301697\n",
      "Epoch [21], last_lr: 0.00025, train_loss: 0.0004, val_loss: 1.2808, val_acc: 0.6864\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5865721702575684\n",
      "val_acc  2 0.7123757600784302\n",
      "val_acc  3 0.9714863896369934\n",
      "val_acc  4 0.7551138997077942\n",
      "val_acc  5 0.9230682253837585\n",
      "val_acc  6 0.5384276509284973\n",
      "val_acc  7 0.8310877680778503\n",
      "val_acc  8 0.8559959530830383\n",
      "val_acc  9 0.6980941295623779\n",
      "Epoch 00022: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [22], last_lr: 0.00013, train_loss: 0.0004, val_loss: 1.2736, val_acc: 0.6862\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5553956627845764\n",
      "val_acc  2 0.761142373085022\n",
      "val_acc  3 0.9186464548110962\n",
      "val_acc  4 0.7919439077377319\n",
      "val_acc  5 0.935049831867218\n",
      "val_acc  6 0.5925418734550476\n",
      "val_acc  7 0.8540140986442566\n",
      "val_acc  8 0.910626232624054\n",
      "val_acc  9 0.5440762639045715\n",
      "Epoch [23], last_lr: 0.00013, train_loss: 0.0004, val_loss: 1.2832, val_acc: 0.6760\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5320006608963013\n",
      "val_acc  2 0.6354818940162659\n",
      "val_acc  3 0.9796494245529175\n",
      "val_acc  4 0.7226017117500305\n",
      "val_acc  5 0.8776805996894836\n",
      "val_acc  6 0.6299251914024353\n",
      "val_acc  7 0.871368408203125\n",
      "val_acc  8 0.8513141870498657\n",
      "val_acc  9 0.6543558835983276\n",
      "Epoch [24], last_lr: 0.00013, train_loss: 0.0004, val_loss: 1.1399, val_acc: 0.7137\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.47970420122146606\n",
      "val_acc  2 0.9488190412521362\n",
      "val_acc  3 0.9041549563407898\n",
      "val_acc  4 0.8543709516525269\n",
      "val_acc  5 0.9387224912643433\n",
      "val_acc  6 0.7190793752670288\n",
      "val_acc  7 0.8277148008346558\n",
      "val_acc  8 0.8610936403274536\n",
      "val_acc  9 0.5460346341133118\n",
      "Epoch [25], last_lr: 0.00013, train_loss: 0.0004, val_loss: 1.3893, val_acc: 0.6451\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5447665452957153\n",
      "val_acc  2 0.6320611238479614\n",
      "val_acc  3 0.9460585713386536\n",
      "val_acc  4 0.8495758175849915\n",
      "val_acc  5 0.9405840039253235\n",
      "val_acc  6 0.47801440954208374\n",
      "val_acc  7 0.7868449091911316\n",
      "val_acc  8 0.8861753344535828\n",
      "val_acc  9 0.38288259506225586\n",
      "Epoch 00026: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch [26], last_lr: 0.00006, train_loss: 0.0003, val_loss: 1.2286, val_acc: 0.6744\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5436060428619385\n",
      "val_acc  2 0.7835375666618347\n",
      "val_acc  3 0.9486896395683289\n",
      "val_acc  4 0.7379263639450073\n",
      "val_acc  5 0.880829930305481\n",
      "val_acc  6 0.6638640761375427\n",
      "val_acc  7 0.8422020077705383\n",
      "val_acc  8 0.8834202885627747\n",
      "val_acc  9 0.45333319902420044\n",
      "Epoch [27], last_lr: 0.00006, train_loss: 0.0004, val_loss: 1.2546, val_acc: 0.6737\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5815819501876831\n",
      "val_acc  2 0.7475253939628601\n",
      "val_acc  3 0.9411800503730774\n",
      "val_acc  4 0.7633476257324219\n",
      "val_acc  5 0.929902195930481\n",
      "val_acc  6 0.6362616419792175\n",
      "val_acc  7 0.80982905626297\n",
      "val_acc  8 0.885964035987854\n",
      "val_acc  9 0.4457979202270508\n",
      "Epoch [28], last_lr: 0.00006, train_loss: 0.0003, val_loss: 1.2069, val_acc: 0.6831\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5492231249809265\n",
      "val_acc  2 0.7283779382705688\n",
      "val_acc  3 0.9860370755195618\n",
      "val_acc  4 0.7813321352005005\n",
      "val_acc  5 0.8909534215927124\n",
      "val_acc  6 0.6905656456947327\n",
      "val_acc  7 0.8579022288322449\n",
      "val_acc  8 0.8406640291213989\n",
      "val_acc  9 0.5043745040893555\n",
      "Epoch [29], last_lr: 0.00006, train_loss: 0.0003, val_loss: 1.1705, val_acc: 0.6908\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5814164280891418\n",
      "val_acc  2 0.7776079177856445\n",
      "val_acc  3 0.938199520111084\n",
      "val_acc  4 0.8046061396598816\n",
      "val_acc  5 0.9144867062568665\n",
      "val_acc  6 0.6573424339294434\n",
      "val_acc  7 0.807822585105896\n",
      "val_acc  8 0.795600414276123\n",
      "val_acc  9 0.6128824949264526\n",
      "Epoch 00030: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch [30], last_lr: 0.00003, train_loss: 0.0003, val_loss: 1.1161, val_acc: 0.7103\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.4995864927768707\n",
      "val_acc  2 0.899319052696228\n",
      "val_acc  3 0.955554187297821\n",
      "val_acc  4 0.7817816734313965\n",
      "val_acc  5 0.9084526896476746\n",
      "val_acc  6 0.7422441840171814\n",
      "val_acc  7 0.8202535510063171\n",
      "val_acc  8 0.92400723695755\n",
      "val_acc  9 0.6105142831802368\n",
      "Epoch [31], last_lr: 0.00003, train_loss: 0.0003, val_loss: 1.1608, val_acc: 0.6820\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5996075868606567\n",
      "val_acc  2 0.7844204902648926\n",
      "val_acc  3 0.9380601644515991\n",
      "val_acc  4 0.7225090265274048\n",
      "val_acc  5 0.9164949655532837\n",
      "val_acc  6 0.7231961488723755\n",
      "val_acc  7 0.8364492654800415\n",
      "val_acc  8 0.9374286532402039\n",
      "val_acc  9 0.3793991804122925\n",
      "Epoch [32], last_lr: 0.00003, train_loss: 0.0003, val_loss: 1.0931, val_acc: 0.7201\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.48307275772094727\n",
      "val_acc  2 0.8804162740707397\n",
      "val_acc  3 0.9213058352470398\n",
      "val_acc  4 0.8468314409255981\n",
      "val_acc  5 0.9463984370231628\n",
      "val_acc  6 0.6784020662307739\n",
      "val_acc  7 0.8983033895492554\n",
      "val_acc  8 0.8850523233413696\n",
      "val_acc  9 0.6499534845352173\n",
      "Epoch [33], last_lr: 0.00003, train_loss: 0.0003, val_loss: 1.1195, val_acc: 0.7063\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.4894203245639801\n",
      "val_acc  2 0.6813093423843384\n",
      "val_acc  3 0.9439142346382141\n",
      "val_acc  4 0.7599393129348755\n",
      "val_acc  5 0.9177244305610657\n",
      "val_acc  6 0.7821781039237976\n",
      "val_acc  7 0.8592294454574585\n",
      "val_acc  8 0.9115197062492371\n",
      "val_acc  9 0.6891686916351318\n",
      "Epoch 00034: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch [34], last_lr: 0.00002, train_loss: 0.0003, val_loss: 1.1137, val_acc: 0.6984\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5228260159492493\n",
      "val_acc  2 0.7598535418510437\n",
      "val_acc  3 0.9089153409004211\n",
      "val_acc  4 0.7811189889907837\n",
      "val_acc  5 0.9239495396614075\n",
      "val_acc  6 0.7351425886154175\n",
      "val_acc  7 0.8942536115646362\n",
      "val_acc  8 0.9108856320381165\n",
      "val_acc  9 0.5501104593276978\n",
      "Epoch [35], last_lr: 0.00002, train_loss: 0.0003, val_loss: 1.0827, val_acc: 0.7080\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5138488411903381\n",
      "val_acc  2 0.7208436727523804\n",
      "val_acc  3 0.9224029779434204\n",
      "val_acc  4 0.7756985425949097\n",
      "val_acc  5 0.9142181277275085\n",
      "val_acc  6 0.7482816576957703\n",
      "val_acc  7 0.8507691621780396\n",
      "val_acc  8 0.8994312286376953\n",
      "val_acc  9 0.7196460366249084\n",
      "Epoch [36], last_lr: 0.00002, train_loss: 0.0003, val_loss: 1.1316, val_acc: 0.6854\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.531459629535675\n",
      "val_acc  2 0.7489196062088013\n",
      "val_acc  3 0.9370667338371277\n",
      "val_acc  4 0.7834938764572144\n",
      "val_acc  5 0.9140621423721313\n",
      "val_acc  6 0.6952099800109863\n",
      "val_acc  7 0.8140946626663208\n",
      "val_acc  8 0.9193598628044128\n",
      "val_acc  9 0.5204032063484192\n",
      "Epoch [37], last_lr: 0.00002, train_loss: 0.0003, val_loss: 1.1027, val_acc: 0.7031\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5155141949653625\n",
      "val_acc  2 0.757571280002594\n",
      "val_acc  3 0.9450345039367676\n",
      "val_acc  4 0.7981539964675903\n",
      "val_acc  5 0.8977495431900024\n",
      "val_acc  6 0.7778791189193726\n",
      "val_acc  7 0.8785021901130676\n",
      "val_acc  8 0.9054597616195679\n",
      "val_acc  9 0.5694237947463989\n",
      "Epoch 00038: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch [38], last_lr: 0.00001, train_loss: 0.0003, val_loss: 1.0600, val_acc: 0.7188\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.4687438905239105\n",
      "val_acc  2 0.8243657946586609\n",
      "val_acc  3 0.9150797724723816\n",
      "val_acc  4 0.813206672668457\n",
      "val_acc  5 0.9370285272598267\n",
      "val_acc  6 0.7635455131530762\n",
      "val_acc  7 0.8971274495124817\n",
      "val_acc  8 0.9114319086074829\n",
      "val_acc  9 0.6573938131332397\n",
      "Epoch [39], last_lr: 0.00001, train_loss: 0.0003, val_loss: 1.1316, val_acc: 0.6967\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.49760833382606506\n",
      "val_acc  2 0.616204023361206\n",
      "val_acc  3 0.9015907049179077\n",
      "val_acc  4 0.8438934087753296\n",
      "val_acc  5 0.9428520202636719\n",
      "val_acc  6 0.7426237463951111\n",
      "val_acc  7 0.9123881459236145\n",
      "val_acc  8 0.8973447680473328\n",
      "val_acc  9 0.5992006063461304\n",
      "Epoch [40], last_lr: 0.00001, train_loss: 0.0003, val_loss: 1.0696, val_acc: 0.7119\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5435301661491394\n",
      "val_acc  2 0.7790263891220093\n",
      "val_acc  3 0.9397308230400085\n",
      "val_acc  4 0.8284947276115417\n",
      "val_acc  5 0.9194766283035278\n",
      "val_acc  6 0.7574071884155273\n",
      "val_acc  7 0.8642638325691223\n",
      "val_acc  8 0.9321807622909546\n",
      "val_acc  9 0.5594677329063416\n",
      "Epoch [41], last_lr: 0.00001, train_loss: 0.0003, val_loss: 1.0784, val_acc: 0.7088\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5028544664382935\n",
      "val_acc  2 0.820629894733429\n",
      "val_acc  3 0.9327491521835327\n",
      "val_acc  4 0.825764536857605\n",
      "val_acc  5 0.9053527116775513\n",
      "val_acc  6 0.8178186416625977\n",
      "val_acc  7 0.8694174885749817\n",
      "val_acc  8 0.9025686383247375\n",
      "val_acc  9 0.5314883589744568\n",
      "Epoch 00042: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch [42], last_lr: 0.00000, train_loss: 0.0003, val_loss: 1.0685, val_acc: 0.7123\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5505492091178894\n",
      "val_acc  2 0.7725979089736938\n",
      "val_acc  3 0.8854717016220093\n",
      "val_acc  4 0.8300766944885254\n",
      "val_acc  5 0.9104750752449036\n",
      "val_acc  6 0.7848048806190491\n",
      "val_acc  7 0.881372332572937\n",
      "val_acc  8 0.9329093098640442\n",
      "val_acc  9 0.5877312421798706\n",
      "Epoch [43], last_lr: 0.00000, train_loss: 0.0003, val_loss: 1.1184, val_acc: 0.6948\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5981031656265259\n",
      "val_acc  2 0.6922566294670105\n",
      "val_acc  3 0.8902560472488403\n",
      "val_acc  4 0.7594784498214722\n",
      "val_acc  5 0.906746506690979\n",
      "val_acc  6 0.7759971618652344\n",
      "val_acc  7 0.8954695463180542\n",
      "val_acc  8 0.882612407207489\n",
      "val_acc  9 0.5441638827323914\n",
      "Epoch [44], last_lr: 0.00000, train_loss: 0.0003, val_loss: 1.0861, val_acc: 0.7085\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5420219302177429\n",
      "val_acc  2 0.778596043586731\n",
      "val_acc  3 0.9196421504020691\n",
      "val_acc  4 0.8140716552734375\n",
      "val_acc  5 0.8995733261108398\n",
      "val_acc  6 0.8108347654342651\n",
      "val_acc  7 0.8828899264335632\n",
      "val_acc  8 0.8918630480766296\n",
      "val_acc  9 0.5668207406997681\n",
      "Epoch [45], last_lr: 0.00000, train_loss: 0.0003, val_loss: 1.1102, val_acc: 0.6970\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5969198346138\n",
      "val_acc  2 0.7491227388381958\n",
      "val_acc  3 0.8994019627571106\n",
      "val_acc  4 0.7800220251083374\n",
      "val_acc  5 0.8678048849105835\n",
      "val_acc  6 0.7507349848747253\n",
      "val_acc  7 0.87702476978302\n",
      "val_acc  8 0.9183987379074097\n",
      "val_acc  9 0.5454968214035034\n",
      "Epoch 00046: reducing learning rate of group 0 to 1.9531e-06.\n",
      "Epoch [46], last_lr: 0.00000, train_loss: 0.0003, val_loss: 1.0772, val_acc: 0.7099\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5473304986953735\n",
      "val_acc  2 0.7217627763748169\n",
      "val_acc  3 0.9342038035392761\n",
      "val_acc  4 0.8123819231987\n",
      "val_acc  5 0.9273297190666199\n",
      "val_acc  6 0.7590233087539673\n",
      "val_acc  7 0.8929572105407715\n",
      "val_acc  8 0.914008617401123\n",
      "val_acc  9 0.5972572565078735\n",
      "Epoch [47], last_lr: 0.00000, train_loss: 0.0003, val_loss: 1.0948, val_acc: 0.7010\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5794605016708374\n",
      "val_acc  2 0.7312266826629639\n",
      "val_acc  3 0.9051712155342102\n",
      "val_acc  4 0.7954260110855103\n",
      "val_acc  5 0.9155635833740234\n",
      "val_acc  6 0.7660706639289856\n",
      "val_acc  7 0.8558763265609741\n",
      "val_acc  8 0.9322201609611511\n",
      "val_acc  9 0.5280206799507141\n",
      "Epoch [48], last_lr: 0.00000, train_loss: 0.0003, val_loss: 1.1065, val_acc: 0.6938\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5979567766189575\n",
      "val_acc  2 0.7136356234550476\n",
      "val_acc  3 0.8952975273132324\n",
      "val_acc  4 0.7908853888511658\n",
      "val_acc  5 0.9185622930526733\n",
      "val_acc  6 0.7153657078742981\n",
      "val_acc  7 0.8776038885116577\n",
      "val_acc  8 0.9331386685371399\n",
      "val_acc  9 0.5158938765525818\n",
      "Epoch [49], last_lr: 0.00000, train_loss: 0.0003, val_loss: 1.1140, val_acc: 0.6959\n",
      "val_acc  0 0.0\n",
      "val_acc  1 0.5482286214828491\n",
      "val_acc  2 0.7399471998214722\n",
      "val_acc  3 0.8974949717521667\n",
      "val_acc  4 0.7922149896621704\n",
      "val_acc  5 0.8862509727478027\n",
      "val_acc  6 0.7812106013298035\n",
      "val_acc  7 0.8899291753768921\n",
      "val_acc  8 0.9520069360733032\n",
      "val_acc  9 0.5384069681167603\n",
      "Epoch 00050: reducing learning rate of group 0 to 9.7656e-07.\n",
      "CPU times: user 18min 45s, sys: 3min 26s, total: 22min 11s\n",
      "Wall time: 1h 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl,\n",
    "                             grad_clip=grad_clip,\n",
    "                             weight_decay=weight_decay,\n",
    "                             opt_func=opt_func, device = device)\n",
    "torch.save(model.state_dict(), \"AllCNN_MNIST_ALL_CLASSES.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a6b2980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T17:50:33.459634Z",
     "iopub.status.busy": "2024-04-21T17:50:33.458800Z",
     "iopub.status.idle": "2024-04-21T17:50:33.492012Z",
     "shell.execute_reply": "2024-04-21T17:50:33.491080Z"
    },
    "papermill": {
     "duration": 0.04738,
     "end_time": "2024-04-21T17:50:33.493963",
     "exception": false,
     "start_time": "2024-04-21T17:50:33.446583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for x in valid_dl:\n",
    "    print(x[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e9d72",
   "metadata": {
    "papermill": {
     "duration": 0.01115,
     "end_time": "2024-04-21T17:50:33.516357",
     "exception": false,
     "start_time": "2024-04-21T17:50:33.505207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4840477,
     "sourceId": 8177135,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4840507,
     "sourceId": 8177174,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4847037,
     "sourceId": 8185799,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4847225,
     "sourceId": 8186083,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3673.630161,
   "end_time": "2024-04-21T17:50:35.743177",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-21T16:49:22.113016",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
