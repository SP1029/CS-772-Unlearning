{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5776c4cd",
   "metadata": {
    "id": "K7GwEjnhDPqh",
    "papermill": {
     "duration": 0.008993,
     "end_time": "2024-04-15T19:55:29.182607",
     "exception": false,
     "start_time": "2024-04-15T19:55:29.173614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc49412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T19:55:29.201340Z",
     "iopub.status.busy": "2024-04-15T19:55:29.201050Z",
     "iopub.status.idle": "2024-04-15T19:55:32.519916Z",
     "shell.execute_reply": "2024-04-15T19:55:32.519133Z"
    },
    "id": "LJrmlufaDRtm",
    "papermill": {
     "duration": 3.33121,
     "end_time": "2024-04-15T19:55:32.522244",
     "exception": false,
     "start_time": "2024-04-15T19:55:29.191034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ConvStandard(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=None, output_padding=0, w_sig =\\\n",
    "                 np.sqrt(1.0)):\n",
    "        super(ConvStandard, self).__init__(in_channels, out_channels,kernel_size)\n",
    "        self.in_channels=in_channels\n",
    "        self.out_channels=out_channels\n",
    "        self.kernel_size=kernel_size\n",
    "        self.stride=stride\n",
    "        self.padding=padding\n",
    "        self.w_sig = w_sig\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.normal_(self.weight, mean=0, std=self.w_sig/(self.in_channels*np.prod(self.kernel_size)))\n",
    "        if self.bias is not None:\n",
    "            torch.nn.init.normal_(self.bias, mean=0, std=0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.conv2d(input,self.weight,self.bias,self.stride,self.padding)\n",
    "\n",
    "class Conv(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=None, output_padding=0,\n",
    "                 activation_fn=nn.ReLU, batch_norm=True, transpose=False):\n",
    "        if padding is None:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        model = []\n",
    "        if not transpose:\n",
    "#             model += [ConvStandard(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "#                                 )]\n",
    "            model += [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                bias=not batch_norm)]\n",
    "        else:\n",
    "            model += [nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding,\n",
    "                                         output_padding=output_padding, bias=not batch_norm)]\n",
    "        if batch_norm:\n",
    "            model += [nn.BatchNorm2d(out_channels, affine=True)]\n",
    "        model += [activation_fn()]\n",
    "        super(Conv, self).__init__(*model)\n",
    "\n",
    "class AllCNN(nn.Module):\n",
    "    def __init__(self, filters_percentage=1., n_channels=3, num_classes=10, dropout=False, batch_norm=True):\n",
    "        super(AllCNN, self).__init__()\n",
    "        n_filter1 = int(96 * filters_percentage)\n",
    "        n_filter2 = int(192 * filters_percentage)\n",
    "\n",
    "        self.conv1 = Conv(n_channels, n_filter1, kernel_size=3, batch_norm=batch_norm)\n",
    "        self.conv2 = Conv(n_filter1, n_filter1, kernel_size=3, batch_norm=batch_norm)\n",
    "        self.conv3 = Conv(n_filter1, n_filter2, kernel_size=3, stride=2, padding=1, batch_norm=batch_norm)\n",
    "\n",
    "        self.dropout1 = self.features = nn.Sequential(nn.Dropout(inplace=True) if dropout else Identity())\n",
    "\n",
    "        self.conv4 = Conv(n_filter2, n_filter2, kernel_size=3, stride=1, batch_norm=batch_norm)\n",
    "        self.conv5 = Conv(n_filter2, n_filter2, kernel_size=3, stride=1, batch_norm=batch_norm)\n",
    "        self.conv6 = Conv(n_filter2, n_filter2, kernel_size=3, stride=2, padding=1, batch_norm=batch_norm)\n",
    "\n",
    "        self.dropout2 = self.features = nn.Sequential(nn.Dropout(inplace=True) if dropout else Identity())\n",
    "\n",
    "        self.conv7 = Conv(n_filter2, n_filter2, kernel_size=3, stride=1, batch_norm=batch_norm)\n",
    "        self.conv8 = Conv(n_filter2, n_filter2, kernel_size=1, stride=1, batch_norm=batch_norm)\n",
    "        if n_channels == 3:\n",
    "            self.pool = nn.AvgPool2d(8)\n",
    "        elif n_channels == 1:\n",
    "            self.pool = nn.AvgPool2d(7)\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_filter2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        actv1 = out\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        actv2 = out\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        actv3 = out\n",
    "\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        out = self.conv4(out)\n",
    "        actv4 = out\n",
    "\n",
    "        out = self.conv5(out)\n",
    "        actv5 = out\n",
    "\n",
    "        out = self.conv6(out)\n",
    "        actv6 = out\n",
    "\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        out = self.conv7(out)\n",
    "        actv7 = out\n",
    "\n",
    "        out = self.conv8(out)\n",
    "        actv8 = out\n",
    "\n",
    "        out = self.pool(out)\n",
    "\n",
    "        out = self.flatten(out)\n",
    "\n",
    "        out = self.classifier(out)\n",
    "\n",
    "        return out, actv1, actv2, actv3, actv4, actv5, actv6, actv7, actv8\n",
    "\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(View, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.view(self.size)\n",
    "\n",
    "\n",
    "class LeNet32(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(LeNet32, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            View((-1, 16*5*5)),\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, n_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x, true_labels=None):\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if idx == 0:\n",
    "                activation1 = x\n",
    "            if idx == 3:\n",
    "                activation2 = x\n",
    "\n",
    "        return x, activation1, activation2\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual block as defined by He et al.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_res1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                                   padding=padding, stride=stride, bias=False)\n",
    "        self.conv_res1_bn = nn.BatchNorm2d(num_features=out_channels, momentum=0.9)\n",
    "        self.conv_res2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                                   padding=padding, bias=False)\n",
    "        self.conv_res2_bn = nn.BatchNorm2d(num_features=out_channels, momentum=0.9)\n",
    "\n",
    "        if stride != 1:\n",
    "            # in case stride is not set to 1, we need to downsample the residual so that\n",
    "            # the dimensions are the same when we add them together\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(num_features=out_channels, momentum=0.9)\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.relu(self.conv_res1_bn(self.conv_res1(x)))\n",
    "        out = self.conv_res2_bn(self.conv_res2(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(residual)\n",
    "\n",
    "        out = self.relu(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    \"\"\"\n",
    "    A Residual network.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=64, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=128, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            ResidualBlock(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=256, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=256, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            ResidualBlock(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(in_features=1024, out_features=10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for idx, layer in enumerate(self.conv):\n",
    "            x = layer(x)\n",
    "            if idx == 0:\n",
    "                activation1 = x\n",
    "            if idx == 3:\n",
    "                activation2 = x\n",
    "            if idx == 8:\n",
    "                activation3 = x\n",
    "            if idx == 12:\n",
    "                activation4 = x\n",
    "\n",
    "        x = x.view(-1, x.shape[1] * x.shape[2] * x.shape[3])\n",
    "        x = self.fc(x)\n",
    "        return x, activation1, activation2, activation3, activation4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0cfc6",
   "metadata": {
    "id": "dQOLxw4aDU6g",
    "papermill": {
     "duration": 0.008208,
     "end_time": "2024-04-15T19:55:32.539073",
     "exception": false,
     "start_time": "2024-04-15T19:55:32.530865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d438499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T19:55:32.557194Z",
     "iopub.status.busy": "2024-04-15T19:55:32.556737Z",
     "iopub.status.idle": "2024-04-15T19:55:32.575549Z",
     "shell.execute_reply": "2024-04-15T19:55:32.574862Z"
    },
    "id": "wkiAg4CNDYFg",
    "papermill": {
     "duration": 0.030111,
     "end_time": "2024-04-15T19:55:32.577434",
     "exception": false,
     "start_time": "2024-04-15T19:55:32.547323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def training_step(model, batch, device):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    out, *_ = model(images)                  # Generate predictions\n",
    "    loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "    return loss\n",
    "\n",
    "def validation_step(model, batch, device):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    out, *_ = model(images)                    # Generate predictions\n",
    "    loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "    acc = accuracy(out, labels)           # Calculate accuracy\n",
    "    return {'Loss': loss.detach(), 'Acc': acc}\n",
    "\n",
    "def validation_epoch_end(model, outputs):\n",
    "    batch_losses = [x['Loss'] for x in outputs]\n",
    "    epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "    batch_accs = [x['Acc'] for x in outputs]\n",
    "    epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "    return {'Loss': epoch_loss.item(), 'Acc': epoch_acc.item()}\n",
    "\n",
    "def epoch_end(model, epoch, result):\n",
    "    print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "        epoch, result['lrs'][-1], result['train_loss'], result['Loss'], result['Acc']))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    outputs = [validation_step(model, batch, device) for batch in val_loader]\n",
    "    return validation_epoch_end(model, outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD, device='cuda'):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = training_step(model, batch, device)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            if grad_clip:\n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            lrs.append(get_lr(optimizer))\n",
    "\n",
    "\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader, device)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        epoch_end(model, epoch, result)\n",
    "        history.append(result)\n",
    "        sched.step(result['Loss'])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec56a65",
   "metadata": {
    "id": "bnP_tORZDcPY",
    "papermill": {
     "duration": 0.008217,
     "end_time": "2024-04-15T19:55:32.593902",
     "exception": false,
     "start_time": "2024-04-15T19:55:32.585685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b6df432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T19:55:32.612773Z",
     "iopub.status.busy": "2024-04-15T19:55:32.612128Z",
     "iopub.status.idle": "2024-04-15T19:55:35.052118Z",
     "shell.execute_reply": "2024-04-15T19:55:35.051312Z"
    },
    "id": "L-dkO84YDdQD",
    "papermill": {
     "duration": 2.452334,
     "end_time": "2024-04-15T19:55:35.054479",
     "exception": false,
     "start_time": "2024-04-15T19:55:32.602145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as tt\n",
    "import tarfile\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.utils import download_url\n",
    "\n",
    "\n",
    "def cifar10(root = './'):\n",
    "    transform = tt.Compose([\n",
    "        tt.ToTensor(),\n",
    "        tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
    "    download_url(dataset_url, '.')\n",
    "\n",
    "    # Extract from archive\n",
    "    with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
    "        tar.extractall(path='./data')\n",
    "\n",
    "    # Look into the data directory\n",
    "    data_dir = os.path.join(root, 'data/cifar10')\n",
    "    #print(os.listdir(data_dir))\n",
    "    #classes = os.listdir(data_dir + \"/train\")\n",
    "\n",
    "    #train_ds = torchvision.datasets.CIFAR10(root='./', train=True, download=True, transform=transform)\n",
    "    #valid_ds = torchvision.datasets.CIFAR10(root='./', train=False, download=True, transform=transform)\n",
    "    train_ds = ImageFolder(data_dir+'/train', transform)\n",
    "    valid_ds = ImageFolder(data_dir+'/test', transform)\n",
    "    return train_ds, valid_ds\n",
    "\n",
    "def svhn(root = './'):\n",
    "    transform = tt.Compose([\n",
    "        tt.ToTensor(),\n",
    "        tt.Normalize((0.4376821, 0.4437697, 0.47280442), (0.19803012, 0.20101562, 0.19703614))\n",
    "    ])\n",
    "\n",
    "    train_ds = torchvision.datasets.SVHN(root='./', train=True, download=True, transform=transform)\n",
    "    valid_ds = torchvision.datasets.SVHN(root='./', train=False, download=True, transform=transform)\n",
    "\n",
    "    return train_ds, valid_ds\n",
    "\n",
    "def mnist(root = './'):\n",
    "    transform = tt.Compose([\n",
    "        tt.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_ds = torchvision.datasets.MNIST(root='./', train=True, download=True, transform=transform)\n",
    "    valid_ds = torchvision.datasets.MNIST(root='./', train=False, download=True, transform=transform)\n",
    "\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a3c4f5",
   "metadata": {
    "id": "lBeno57iDd6X",
    "papermill": {
     "duration": 0.008468,
     "end_time": "2024-04-15T19:55:35.071856",
     "exception": false,
     "start_time": "2024-04-15T19:55:35.063388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metric.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75196903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T19:55:35.090336Z",
     "iopub.status.busy": "2024-04-15T19:55:35.089700Z",
     "iopub.status.idle": "2024-04-15T19:55:36.331613Z",
     "shell.execute_reply": "2024-04-15T19:55:36.330847Z"
    },
    "id": "PZNxNtbqDg93",
    "papermill": {
     "duration": 1.253489,
     "end_time": "2024-04-15T19:55:36.333946",
     "exception": false,
     "start_time": "2024-04-15T19:55:35.080457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def entropy(p, dim = -1, keepdim = False):\n",
    "    return -torch.where(p > 0, p * p.log(), p.new([0.0])).sum(dim=dim, keepdim=keepdim)\n",
    "\n",
    "def collect_prob(data_loader, model):\n",
    "    data_loader = torch.utils.data.DataLoader(data_loader.dataset, batch_size=1, shuffle=False, num_workers = 32, prefetch_factor = 10)\n",
    "    prob = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = [tensor.to(next(model.parameters()).device) for tensor in batch]\n",
    "            data, _, target = batch\n",
    "            output = model(data)\n",
    "            prob.append(F.softmax(output, dim=-1).data)\n",
    "    return torch.cat(prob)\n",
    "\n",
    "def get_membership_attack_data(retain_loader, forget_loader, test_loader, model):\n",
    "    retain_prob = collect_prob(retain_loader, model)\n",
    "    forget_prob = collect_prob(forget_loader, model)\n",
    "    test_prob = collect_prob(test_loader, model)\n",
    "\n",
    "    X_r = torch.cat([entropy(retain_prob), entropy(test_prob)]).cpu().numpy().reshape(-1, 1)\n",
    "    Y_r = np.concatenate([np.ones(len(retain_prob)), np.zeros(len(test_prob))])\n",
    "\n",
    "    X_f = entropy(forget_prob).cpu().numpy().reshape(-1, 1)\n",
    "    Y_f = np.concatenate([np.ones(len(forget_prob))])\n",
    "    return X_f, Y_f, X_r, Y_r\n",
    "\n",
    "def get_membership_attack_prob(retain_loader, forget_loader, test_loader, model):\n",
    "    X_f, Y_f, X_r, Y_r = get_membership_attack_data(retain_loader, forget_loader, test_loader, model)\n",
    "    clf = SVC(C=3,gamma='auto',kernel='rbf')\n",
    "    #clf = LogisticRegression(class_weight='balanced',solver='lbfgs',multi_class='multinomial')\n",
    "    clf.fit(X_r, Y_r)\n",
    "    results = clf.predict(X_f)\n",
    "    return results.mean()\n",
    "\n",
    "def relearn_time(model, train_loader, valid_loader, reqAcc, lr):\n",
    "    # measuring relearn time for gold standard model\n",
    "    rltime = 0\n",
    "    curr_Acc = 0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    # we will try the relearning step till 4 epochs.\n",
    "    for epoch in range(10):\n",
    "\n",
    "        for batch in train_loader:\n",
    "            model.train()\n",
    "            loss = training_step(model, batch)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            history = [evaluate(model, valid_dl)]\n",
    "            curr_Acc = history[0][\"Acc\"]*100\n",
    "            print(curr_Acc, sep=',')\n",
    "\n",
    "\n",
    "\n",
    "            rltime += 1\n",
    "            if(curr_Acc >= reqAcc):\n",
    "                break\n",
    "\n",
    "        if(curr_Acc >= reqAcc):\n",
    "            break\n",
    "    return rltime\n",
    "\n",
    "def ain(full_model, model, gold_model, train_data, val_retain, val_forget,\n",
    "                  batch_size = 256, error_range = 0.05, lr = 0.001):\n",
    "    # measuring performance of fully trained model on forget class\n",
    "    forget_valid_dl = DataLoader(val_forget, batch_size)\n",
    "    history = [evaluate(full_model, forget_valid_dl)]\n",
    "    AccForget = history[0][\"Acc\"]*100\n",
    "\n",
    "    print(\"Accuracy of fully trained model on forget set is: {}\".format(AccForget))\n",
    "\n",
    "    retain_valid_dl = DataLoader(val_retain, batch_size)\n",
    "    history = [evaluate(full_model, retain_valid_dl)]\n",
    "    AccRetain = history[0][\"Acc\"]*100\n",
    "\n",
    "    print(\"Accuracy of fully trained model on retain set is: {}\".format(AccRetain))\n",
    "\n",
    "    history = [evaluate(model, forget_valid_dl)]\n",
    "    AccForget_Fmodel = history[0][\"Acc\"]*100\n",
    "\n",
    "    print(\"Accuracy of forget model on forget set is: {}\".format(AccForget_Fmodel))\n",
    "\n",
    "    history = [evaluate(model, retain_valid_dl)]\n",
    "    AccRetain_Fmodel = history[0][\"Acc\"]*100\n",
    "\n",
    "    print(\"Accuracy of forget model on retain set is: {}\".format(AccRetain_Fmodel))\n",
    "\n",
    "    history = [evaluate(gold_model, forget_valid_dl)]\n",
    "    AccForget_Gmodel = history[0][\"Acc\"]*100\n",
    "\n",
    "    print(\"Accuracy of gold model on forget set is: {}\".format(AccForget_Gmodel))\n",
    "\n",
    "    history = [evaluate(gold_model, retain_valid_dl)]\n",
    "    AccRetain_Gmodel = history[0][\"Acc\"]*100\n",
    "\n",
    "    print(\"Accuracy of gold model on retain set is: {}\".format(AccRetain_Gmodel))\n",
    "\n",
    "    reqAccF = (1-error_range)*AccForget\n",
    "\n",
    "    print(\"Desired Accuracy for retrain time with error range {} is {}\".format(error_range, reqAccF))\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size, shuffle = True)\n",
    "    valid_loader = DataLoader(val_forget, batch_size)\n",
    "    rltime_gold = relearn_time(model = gold_model, train_loader = train_loader, valid_loader = valid_loader,\n",
    "                               reqAcc = reqAccF,  lr = lr)\n",
    "\n",
    "    print(\"Relearning time for Gold Standard Model is {}\".format(rltime_gold))\n",
    "\n",
    "    rltime_forget = relearn_time(model = model, train_loader = train_loader, valid_loader = valid_loader,\n",
    "                               reqAcc = reqAccF, lr = lr)\n",
    "\n",
    "    print(\"Relearning time for Forget Model is {}\".format(rltime_forget))\n",
    "\n",
    "    rl_coeff = rltime_forget/rltime_gold\n",
    "    print(\"AIN = {}\".format(rl_coeff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40bbae3",
   "metadata": {
    "id": "tvm7S3SVDhpf",
    "papermill": {
     "duration": 0.008237,
     "end_time": "2024-04-15T19:55:36.350782",
     "exception": false,
     "start_time": "2024-04-15T19:55:36.342545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Unlearn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee60563",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T19:55:36.369244Z",
     "iopub.status.busy": "2024-04-15T19:55:36.368827Z",
     "iopub.status.idle": "2024-04-15T19:55:36.392176Z",
     "shell.execute_reply": "2024-04-15T19:55:36.391476Z"
    },
    "id": "-C3moEJZDpXn",
    "papermill": {
     "duration": 0.034686,
     "end_time": "2024-04-15T19:55:36.393923",
     "exception": false,
     "start_time": "2024-04-15T19:55:36.359237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def attention(x):\n",
    "        \"\"\"\n",
    "        Taken from https://github.com/szagoruyko/attention-transfer\n",
    "        :param x = activations\n",
    "        \"\"\"\n",
    "        return F.normalize(x.pow(2).mean(1).view(x.size(0), -1))\n",
    "\n",
    "\n",
    "def attention_diff(x, y):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/szagoruyko/attention-transfer\n",
    "    :param x = activations\n",
    "    :param y = activations\n",
    "    \"\"\"\n",
    "    return (attention(x) - attention(y)).pow(2).mean()\n",
    "\n",
    "\n",
    "def divergence(student_logits, teacher_logits, KL_temperature):\n",
    "    divergence = F.kl_div(F.log_softmax(student_logits / KL_temperature, dim=1), F.softmax(teacher_logits / KL_temperature, dim=1))  # forward KL\n",
    "\n",
    "    return divergence\n",
    "\n",
    "\n",
    "def KT_loss_generator(student_logits, teacher_logits, KL_temperature):\n",
    "\n",
    "    divergence_loss = divergence(student_logits, teacher_logits, KL_temperature)\n",
    "    total_loss = - divergence_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def KT_loss_student(student_logits, student_activations, teacher_logits, teacher_activations, KL_temperature = 1, AT_beta = 250):\n",
    "\n",
    "    divergence_loss = divergence(student_logits, teacher_logits, KL_temperature)\n",
    "    if AT_beta > 0:\n",
    "        at_loss = 0\n",
    "        for i in range(len(student_activations)):\n",
    "            at_loss = at_loss + AT_beta * attention_diff(student_activations[i], teacher_activations[i])\n",
    "    else:\n",
    "        at_loss = 0        \n",
    "        \n",
    "    # Masking Student Attention\n",
    "    at_loss = 0\n",
    "    total_loss = divergence_loss + at_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim, num_channels = 3):\n",
    "        super(Generator, self).__init__()\n",
    "        prefinal_layer = None\n",
    "        final_layer = None\n",
    "        if num_channels == 3:\n",
    "            prefinal_layer = nn.Conv2d(64, 3, 3, stride=1, padding=1)\n",
    "            final_layer = nn.BatchNorm2d(3, affine=True)\n",
    "        elif num_channels == 1:\n",
    "            prefinal_layer = nn.Conv2d(64, 1, 7, stride=1, padding=1)\n",
    "            final_layer = nn.BatchNorm2d(1, affine=True)\n",
    "        else:\n",
    "            print(f\"Generator Not Supported for {num_channels} channels\")\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(z_dim, 128 * 8**2),\n",
    "            View((-1, 128, 8, 8)),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            prefinal_layer,\n",
    "            final_layer\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.layers(z)\n",
    "\n",
    "    def print_shape(self, x):\n",
    "        \"\"\"\n",
    "        For debugging purposes\n",
    "        \"\"\"\n",
    "        act = x\n",
    "        for layer in self.layers:\n",
    "            act = layer(act)\n",
    "            print('\\n', layer, '---->', act.shape)\n",
    "\n",
    "\n",
    "class LearnableLoader(nn.Module):\n",
    "    def __init__(self, n_repeat_batch, num_channels = 3,device='cuda'):\n",
    "        \"\"\"\n",
    "        Infinite loader, which contains a learnable generator.\n",
    "        \"\"\"\n",
    "\n",
    "        super(LearnableLoader, self).__init__()\n",
    "        self.batch_size = 256\n",
    "        self.n_repeat_batch = n_repeat_batch\n",
    "        self.z_dim = 128\n",
    "        self.generator = Generator(self.z_dim, num_channels=num_channels).to(device=device)\n",
    "        self.device = device\n",
    "\n",
    "        self._running_repeat_batch_idx = 0\n",
    "        self.z = torch.randn((self.batch_size, self.z_dim)).to(device=self.device)\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._running_repeat_batch_idx == self.n_repeat_batch:\n",
    "            self.z = torch.randn((self.batch_size, self.z_dim)).to(device=self.device)\n",
    "            self._running_repeat_batch_idx = 0\n",
    "\n",
    "        images = self.generator(self.z)\n",
    "        self._running_repeat_batch_idx += 1\n",
    "        return images\n",
    "\n",
    "    def samples(self, n, grid=True):\n",
    "        \"\"\"\n",
    "        :return: if grid returns single grid image, else\n",
    "        returns n images.\n",
    "        \"\"\"\n",
    "        self.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn((n, self.z_dim)).to(device=self.device)\n",
    "            images = visualize(self.generator(z), dataset=self.dataset).cpu()\n",
    "            if grid:\n",
    "                images = make_grid(images, nrow=round(math.sqrt(n)), normalize=True)\n",
    "\n",
    "        self.generator.train()\n",
    "        return images\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df342f5a",
   "metadata": {
    "id": "yywXC9m8Dwsn",
    "papermill": {
     "duration": 0.008152,
     "end_time": "2024-04-15T19:55:36.410301",
     "exception": false,
     "start_time": "2024-04-15T19:55:36.402149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7eded54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T19:55:36.428591Z",
     "iopub.status.busy": "2024-04-15T19:55:36.427888Z",
     "iopub.status.idle": "2024-04-15T19:55:37.078772Z",
     "shell.execute_reply": "2024-04-15T19:55:37.077728Z"
    },
    "id": "_shdf4zqDx7E",
    "outputId": "f3b0ef52-6612-40ca-ecaa-9ccb12adb386",
    "papermill": {
     "duration": 0.662513,
     "end_time": "2024-04-15T19:55:37.081077",
     "exception": false,
     "start_time": "2024-04-15T19:55:36.418564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7e5bfd927690>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necessary Imports\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cef1434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T19:55:37.100279Z",
     "iopub.status.busy": "2024-04-15T19:55:37.099844Z",
     "iopub.status.idle": "2024-04-15T19:55:38.042876Z",
     "shell.execute_reply": "2024-04-15T19:55:38.041867Z"
    },
    "id": "iRqF7H5gD3de",
    "outputId": "85a85f6c-c858-4cac-82ed-56e3ec29628c",
    "papermill": {
     "duration": 0.954888,
     "end_time": "2024-04-15T19:55:38.044926",
     "exception": false,
     "start_time": "2024-04-15T19:55:37.090038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 130433194.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 50076764.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 39616723.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 8550506.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_ds, valid_ds = mnist()\n",
    "\n",
    "batch_size = 256\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=16)\n",
    "valid_dl = DataLoader(valid_ds, batch_size, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4508ce2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T19:55:38.066434Z",
     "iopub.status.busy": "2024-04-15T19:55:38.066169Z",
     "iopub.status.idle": "2024-04-15T19:55:45.496741Z",
     "shell.execute_reply": "2024-04-15T19:55:45.495959Z"
    },
    "id": "ZmbnP8ozD38G",
    "papermill": {
     "duration": 7.443913,
     "end_time": "2024-04-15T19:55:45.499084",
     "exception": false,
     "start_time": "2024-04-15T19:55:38.055171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "classwise_train = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_train[i] = []\n",
    "\n",
    "for img, label in train_ds:\n",
    "    classwise_train[label].append((img, label))\n",
    "\n",
    "classwise_test = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_test[i] = []\n",
    "\n",
    "for img, label in valid_ds:\n",
    "    classwise_test[label].append((img, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f6fea27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T19:55:45.521242Z",
     "iopub.status.busy": "2024-04-15T19:55:45.520650Z",
     "iopub.status.idle": "2024-04-15T19:55:45.524746Z",
     "shell.execute_reply": "2024-04-15T19:55:45.523844Z"
    },
    "id": "0I3jnEXID5LW",
    "papermill": {
     "duration": 0.016977,
     "end_time": "2024-04-15T19:55:45.526571",
     "exception": false,
     "start_time": "2024-04-15T19:55:45.509594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6731205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T19:55:45.548445Z",
     "iopub.status.busy": "2024-04-15T19:55:45.547821Z",
     "iopub.status.idle": "2024-04-15T19:55:45.792184Z",
     "shell.execute_reply": "2024-04-15T19:55:45.791011Z"
    },
    "id": "sLQnr5ivD67r",
    "papermill": {
     "duration": 0.257451,
     "end_time": "2024-04-15T19:55:45.794524",
     "exception": false,
     "start_time": "2024-04-15T19:55:45.537073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AllCNN(n_channels = 1).to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00e5cd2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T19:55:45.816425Z",
     "iopub.status.busy": "2024-04-15T19:55:45.816090Z",
     "iopub.status.idle": "2024-04-15T19:55:45.820606Z",
     "shell.execute_reply": "2024-04-15T19:55:45.819759Z"
    },
    "id": "-IDTJ9JAD8Ao",
    "papermill": {
     "duration": 0.01744,
     "end_time": "2024-04-15T19:55:45.822415",
     "exception": false,
     "start_time": "2024-04-15T19:55:45.804975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce8a5a67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T19:55:45.843999Z",
     "iopub.status.busy": "2024-04-15T19:55:45.843474Z",
     "iopub.status.idle": "2024-04-15T20:01:17.590181Z",
     "shell.execute_reply": "2024-04-15T20:01:17.588900Z"
    },
    "id": "rjIm1PW6D9jV",
    "outputId": "285fee58-daff-44d3-b8a1-a303be48637b",
    "papermill": {
     "duration": 331.759796,
     "end_time": "2024-04-15T20:01:17.592329",
     "exception": false,
     "start_time": "2024-04-15T19:55:45.832533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.01000, train_loss: 0.2741, val_loss: 0.3044, val_acc: 0.9021\n",
      "Epoch [1], last_lr: 0.01000, train_loss: 0.0710, val_loss: 0.1794, val_acc: 0.9481\n",
      "Epoch [2], last_lr: 0.01000, train_loss: 0.0598, val_loss: 0.0632, val_acc: 0.9816\n",
      "Epoch [3], last_lr: 0.01000, train_loss: 0.0522, val_loss: 0.2402, val_acc: 0.9307\n",
      "Epoch [4], last_lr: 0.01000, train_loss: 0.0450, val_loss: 0.0890, val_acc: 0.9716\n",
      "Epoch [5], last_lr: 0.01000, train_loss: 0.0416, val_loss: 0.1271, val_acc: 0.9602\n",
      "Epoch [6], last_lr: 0.01000, train_loss: 0.0386, val_loss: 0.0717, val_acc: 0.9788\n",
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch [7], last_lr: 0.00500, train_loss: 0.0239, val_loss: 0.0228, val_acc: 0.9931\n",
      "Epoch [8], last_lr: 0.00500, train_loss: 0.0232, val_loss: 0.0288, val_acc: 0.9912\n",
      "Epoch [9], last_lr: 0.00500, train_loss: 0.0238, val_loss: 0.0229, val_acc: 0.9926\n",
      "Epoch [10], last_lr: 0.00500, train_loss: 0.0247, val_loss: 0.0214, val_acc: 0.9937\n",
      "Epoch [11], last_lr: 0.00500, train_loss: 0.0213, val_loss: 0.0203, val_acc: 0.9936\n",
      "Epoch [12], last_lr: 0.00500, train_loss: 0.0242, val_loss: 0.0845, val_acc: 0.9726\n",
      "Epoch [13], last_lr: 0.00500, train_loss: 0.0214, val_loss: 0.0296, val_acc: 0.9902\n",
      "Epoch [14], last_lr: 0.00500, train_loss: 0.0220, val_loss: 0.0301, val_acc: 0.9902\n",
      "Epoch [15], last_lr: 0.00500, train_loss: 0.0199, val_loss: 0.0287, val_acc: 0.9911\n",
      "Epoch 00016: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch [16], last_lr: 0.00250, train_loss: 0.0132, val_loss: 0.0176, val_acc: 0.9943\n",
      "Epoch [17], last_lr: 0.00250, train_loss: 0.0101, val_loss: 0.0188, val_acc: 0.9942\n",
      "Epoch [18], last_lr: 0.00250, train_loss: 0.0098, val_loss: 0.0247, val_acc: 0.9925\n",
      "Epoch [19], last_lr: 0.00250, train_loss: 0.0110, val_loss: 0.0195, val_acc: 0.9938\n",
      "Epoch [20], last_lr: 0.00250, train_loss: 0.0116, val_loss: 0.0207, val_acc: 0.9937\n",
      "Epoch 00021: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch [21], last_lr: 0.00125, train_loss: 0.0060, val_loss: 0.0140, val_acc: 0.9955\n",
      "Epoch [22], last_lr: 0.00125, train_loss: 0.0042, val_loss: 0.0128, val_acc: 0.9959\n",
      "Epoch [23], last_lr: 0.00125, train_loss: 0.0039, val_loss: 0.0157, val_acc: 0.9950\n",
      "Epoch [24], last_lr: 0.00125, train_loss: 0.0040, val_loss: 0.0179, val_acc: 0.9941\n",
      "CPU times: user 4min 43s, sys: 17.9 s, total: 5min 1s\n",
      "Wall time: 5min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl,\n",
    "                             grad_clip=grad_clip,\n",
    "                             weight_decay=weight_decay,\n",
    "                             opt_func=opt_func, device = device)\n",
    "torch.save(model.state_dict(), \"AllCNN_MNIST_ALL_CLASSES.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f851d110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T20:01:17.618456Z",
     "iopub.status.busy": "2024-04-15T20:01:17.617641Z",
     "iopub.status.idle": "2024-04-15T20:01:19.017296Z",
     "shell.execute_reply": "2024-04-15T20:01:19.016211Z"
    },
    "id": "YNRw3ytAD_C6",
    "outputId": "276bf20c-4961-439d-e254-8dced20b7fc5",
    "papermill": {
     "duration": 1.414823,
     "end_time": "2024-04-15T20:01:19.019354",
     "exception": false,
     "start_time": "2024-04-15T20:01:17.604531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Loss': 0.017896613106131554, 'Acc': 0.994140625}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"AllCNN_MNIST_ALL_CLASSES.pt\"))\n",
    "history = [evaluate(model, valid_dl, device = device)]\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf77b7",
   "metadata": {
    "id": "qq6K1RKnECal",
    "papermill": {
     "duration": 0.012026,
     "end_time": "2024-04-15T20:01:19.044099",
     "exception": false,
     "start_time": "2024-04-15T20:01:19.032073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Forgetting Class 0 using GKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1c334f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T20:01:19.069506Z",
     "iopub.status.busy": "2024-04-15T20:01:19.069160Z",
     "iopub.status.idle": "2024-04-15T20:01:19.081889Z",
     "shell.execute_reply": "2024-04-15T20:01:19.081067Z"
    },
    "id": "DoHVTWKJEAPa",
    "outputId": "90429c97-8d95-4944-ba4d-29bb30397889",
    "papermill": {
     "duration": 0.02766,
     "end_time": "2024-04-15T20:01:19.083723",
     "exception": false,
     "start_time": "2024-04-15T20:01:19.056063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the forget and retain data\n",
    "forget_valid = []\n",
    "forget_classes = [0]\n",
    "for cls in range(num_classes):\n",
    "    if cls in forget_classes:\n",
    "        for img, label in classwise_test[cls]:\n",
    "            forget_valid.append((img, label))\n",
    "\n",
    "retain_valid = []\n",
    "for cls in range(num_classes):\n",
    "    if cls not in forget_classes:\n",
    "        for img, label in classwise_test[cls]:\n",
    "            retain_valid.append((img, label))\n",
    "\n",
    "forget_valid_dl = DataLoader(forget_valid, batch_size, num_workers=3, pin_memory=True)\n",
    "\n",
    "retain_valid_dl = DataLoader(retain_valid, batch_size, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e859a1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T20:01:19.109073Z",
     "iopub.status.busy": "2024-04-15T20:01:19.108769Z",
     "iopub.status.idle": "2024-04-15T20:01:19.112616Z",
     "shell.execute_reply": "2024-04-15T20:01:19.111846Z"
    },
    "id": "pafNKdIsEHwA",
    "papermill": {
     "duration": 0.018662,
     "end_time": "2024-04-15T20:01:19.114452",
     "exception": false,
     "start_time": "2024-04-15T20:01:19.095790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_generator_iter = 1\n",
    "n_student_iter = 10\n",
    "n_repeat_batch = n_generator_iter + n_student_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6a79d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T20:01:19.140362Z",
     "iopub.status.busy": "2024-04-15T20:01:19.139740Z",
     "iopub.status.idle": "2024-04-15T20:01:19.213856Z",
     "shell.execute_reply": "2024-04-15T20:01:19.213179Z"
    },
    "id": "f5hetsYZEITE",
    "papermill": {
     "duration": 0.089155,
     "end_time": "2024-04-15T20:01:19.215796",
     "exception": false,
     "start_time": "2024-04-15T20:01:19.126641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AllCNN(n_channels = 1).to(device = device)\n",
    "model.load_state_dict(torch.load(\"AllCNN_MNIST_ALL_CLASSES.pt\"))\n",
    "\n",
    "student = AllCNN(n_channels = 1).to(device = device)\n",
    "generator = LearnableLoader(n_repeat_batch=n_repeat_batch, num_channels = 1, device = device).to(device=device)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "scheduler_generator = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_generator,\n",
    "                                                               mode='min', factor=0.5, patience=2, verbose=True)\n",
    "optimizer_student = torch.optim.Adam(student.parameters(), lr=0.001)\n",
    "scheduler_student = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_student, \\\n",
    "                                    mode='min', factor=0.5, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5044c87d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T20:01:19.241374Z",
     "iopub.status.busy": "2024-04-15T20:01:19.241108Z",
     "iopub.status.idle": "2024-04-15T20:01:20.786978Z",
     "shell.execute_reply": "2024-04-15T20:01:20.785912Z"
    },
    "id": "8Tc05Ck8EUNe",
    "outputId": "89738707-24f7-4768-eca8-fb978b705f06",
    "papermill": {
     "duration": 1.561219,
     "end_time": "2024-04-15T20:01:20.789279",
     "exception": false,
     "start_time": "2024-04-15T20:01:19.228060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Fully Trained Model on Forget Class\n",
      "Accuracy: 99.51171875\n",
      "Loss: 0.013258367776870728\n",
      "Performance of Fully Trained Model on Retain Class\n",
      "Accuracy: 99.33232069015503\n",
      "Loss: 0.021980782970786095\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance of Fully Trained Model on Forget Class\")\n",
    "history = [evaluate(model, forget_valid_dl, device = device)]\n",
    "print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "print(\"Loss: {}\".format(history[0][\"Loss\"]))\n",
    "\n",
    "print(\"Performance of Fully Trained Model on Retain Class\")\n",
    "history = [evaluate(model, retain_valid_dl, device = device)]\n",
    "print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "print(\"Loss: {}\".format(history[0][\"Loss\"]))\n",
    "\n",
    "\n",
    "history = [evaluate(student, forget_valid_dl, device = device)]\n",
    "AccForget = history[0][\"Acc\"]*100\n",
    "ErrForget = history[0][\"Loss\"]\n",
    "\n",
    "history = [evaluate(student, retain_valid_dl, device = device)]\n",
    "AccRetain = history[0][\"Acc\"]*100\n",
    "ErrRetain = history[0][\"Loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d88126fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T20:01:20.817662Z",
     "iopub.status.busy": "2024-04-15T20:01:20.816857Z",
     "iopub.status.idle": "2024-04-15T20:01:20.822722Z",
     "shell.execute_reply": "2024-04-15T20:01:20.821996Z"
    },
    "id": "bndt1dOWEWuO",
    "papermill": {
     "duration": 0.022214,
     "end_time": "2024-04-15T20:01:20.824584",
     "exception": false,
     "start_time": "2024-04-15T20:01:20.802370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator_path = \"./ckpts/mnist_allcnn/generator\"\n",
    "student_path = \"./ckpts/mnist_allcnn/student\"\n",
    "\n",
    "os.makedirs(generator_path)\n",
    "os.makedirs(student_path)\n",
    "\n",
    "idx_pseudo = 0\n",
    "total_n_pseudo_batches = 4000\n",
    "n_pseudo_batches = 0\n",
    "running_gen_loss = []\n",
    "running_stu_loss = []\n",
    "\n",
    "threshold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e64f5477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T20:01:20.851252Z",
     "iopub.status.busy": "2024-04-15T20:01:20.850967Z",
     "iopub.status.idle": "2024-04-15T20:01:20.856013Z",
     "shell.execute_reply": "2024-04-15T20:01:20.855307Z"
    },
    "id": "g6jh_lEtEX7o",
    "papermill": {
     "duration": 0.020578,
     "end_time": "2024-04-15T20:01:20.857755",
     "exception": false,
     "start_time": "2024-04-15T20:01:20.837177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e97e4",
   "metadata": {
    "id": "2wUbvWU-Ebmv",
    "papermill": {
     "duration": 0.012364,
     "end_time": "2024-04-15T20:01:20.882632",
     "exception": false,
     "start_time": "2024-04-15T20:01:20.870268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training the unlearned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d68acac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T20:01:20.908882Z",
     "iopub.status.busy": "2024-04-15T20:01:20.908602Z",
     "iopub.status.idle": "2024-04-15T20:01:20.912298Z",
     "shell.execute_reply": "2024-04-15T20:01:20.911538Z"
    },
    "id": "78mefkmfEZbO",
    "papermill": {
     "duration": 0.018872,
     "end_time": "2024-04-15T20:01:20.914079",
     "exception": false,
     "start_time": "2024-04-15T20:01:20.895207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "KL_temperature = 1\n",
    "AT_beta = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "567e4fae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T20:01:20.940323Z",
     "iopub.status.busy": "2024-04-15T20:01:20.940085Z",
     "iopub.status.idle": "2024-04-15T20:01:20.944592Z",
     "shell.execute_reply": "2024-04-15T20:01:20.943798Z"
    },
    "id": "-0oe1W_gY3p8",
    "papermill": {
     "duration": 0.019787,
     "end_time": "2024-04-15T20:01:20.946395",
     "exception": false,
     "start_time": "2024-04-15T20:01:20.926608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_entropy(probs):\n",
    "      myprobs = torch.nn.functional.softmax(probs)\n",
    "      sum = 0\n",
    "      for p in myprobs:\n",
    "        sum+=float((-p) * torch.log(p))\n",
    "      return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac6f0687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T20:01:20.973038Z",
     "iopub.status.busy": "2024-04-15T20:01:20.972781Z",
     "iopub.status.idle": "2024-04-15T23:11:08.461409Z",
     "shell.execute_reply": "2024-04-15T23:11:08.460231Z"
    },
    "id": "g1d2H5OiEeGW",
    "outputId": "9114a114-0ac1-4310-d194-b7206fea30dc",
    "papermill": {
     "duration": 11387.505055,
     "end_time": "2024-04-15T23:11:08.464125",
     "exception": false,
     "start_time": "2024-04-15T20:01:20.959070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "1     0.0        0.0  10.568576   2.373552   2.302127          -0.212092   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "1         0.186562  \n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "2    50.0        0.0  10.655382   7.208605   3.182864          -0.109862   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "2         0.123661  \n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "3   100.0        0.0  17.784289   6.025998   2.372615          -0.091117   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "3         0.097504  \n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "4   150.0        0.0  13.953993   5.333289   2.257123          -0.077688   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "4         0.074023  \n",
      "Epoch 00004: reducing learning rate of group 0 to 5.0000e-04.\n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "5   200.0        0.0  18.999566   4.504591   2.297622          -0.074948   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "5         0.059415  \n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "6   250.0        0.0  38.216147   4.422337   1.959657          -0.069763   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "6         0.055579  \n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "7   300.0        0.0  18.825954   6.328003   2.934484          -0.065271   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "7         0.050637  \n",
      "Epoch 00007: reducing learning rate of group 0 to 2.5000e-04.\n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "8   350.0        0.0  31.868491   4.139145   2.024839          -0.067512   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "8         0.044721  \n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "9   400.0        0.0  25.358072   3.891856   1.986885          -0.060654   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "9         0.040773  \n",
      "Epoch 00009: reducing learning rate of group 0 to 5.0000e-04.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "10   450.0        0.0  25.802952   7.088564   2.360746          -0.056049   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "10         0.045797  \n",
      "Epoch 00010: reducing learning rate of group 0 to 1.2500e-04.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "11   500.0        0.0  34.819877   4.425354   2.063575          -0.057182   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "11         0.041018  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "12   550.0        0.0  38.747829   4.920764   2.050687          -0.057987   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "12         0.040448  \n",
      "Epoch 00012: reducing learning rate of group 0 to 2.5000e-04.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "13   600.0        0.0  27.886283   6.899304   2.477624          -0.051221   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "13         0.043765  \n",
      "Epoch 00013: reducing learning rate of group 0 to 6.2500e-05.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "14   650.0        0.0  35.004342   4.918982   2.060542          -0.049774   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "14         0.040235  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "15   700.0        0.0  41.384548   4.884907   1.966202          -0.049869   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "15         0.039687  \n",
      "Epoch 00015: reducing learning rate of group 0 to 1.2500e-04.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "16   750.0        0.0  33.387586   5.533535   2.056223          -0.045524   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "16         0.040228  \n",
      "Epoch 00016: reducing learning rate of group 0 to 3.1250e-05.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "17   800.0        0.0  41.221789   4.561756   1.837064          -0.044719   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "17          0.03823  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "18   850.0        0.0  34.950086   5.598623   2.075523          -0.043932   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "18          0.03731  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "19   900.0        0.0  36.534289   5.328032   2.004816          -0.043826   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "19         0.037045  \n",
      "Epoch 00019: reducing learning rate of group 0 to 1.5625e-05.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "20   950.0        0.0  43.424478   4.893451   1.820865          -0.042909   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "20         0.035716  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "21  1000.0        0.0  39.442274   4.680348    1.87189          -0.042995   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "21          0.03565  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "22  1050.0        0.0  41.156685   4.867988   1.775543          -0.042241   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "22         0.035009  \n",
      "Epoch 00022: reducing learning rate of group 0 to 7.8125e-06.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "23  1100.0        0.0  37.554252   5.232343   1.938733          -0.042984   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "23         0.035719  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "24  1150.0        0.0  38.519967   5.975959    2.08285          -0.042085   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "24         0.034507  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "25  1200.0        0.0  40.972221   6.234999   2.096292          -0.041098   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "25         0.033752  \n",
      "Epoch 00025: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch 00025: reducing learning rate of group 0 to 3.9063e-06.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "26  1250.0        0.0  43.185765   5.627654   1.951247          -0.040754   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "26         0.036027  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "27  1300.0        0.0   41.88368   5.610244   1.968635           -0.03843   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "27         0.034194  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "28  1350.0        0.0  42.339408   5.965589   2.019534           -0.03871   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "28         0.034316  \n",
      "Epoch 00028: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch 00028: reducing learning rate of group 0 to 1.9531e-06.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "29  1400.0        0.0  43.478733    5.47754    1.92401           -0.03798   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "29          0.03498  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "30  1450.0        0.0  39.246961   5.921145   2.012923          -0.037512   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "30         0.034993  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "31  1500.0        0.0  40.223524   5.902458   2.050725           -0.03572   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "31         0.033476  \n",
      "Epoch 00031: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch 00031: reducing learning rate of group 0 to 9.7656e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "32  1550.0        0.0   40.76606   5.727962   2.025576          -0.035441   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "32         0.034153  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "33  1600.0        0.0  40.646702   5.771301   2.011549          -0.033986   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "33         0.032724  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "34  1650.0        0.0  42.089844   5.755216   2.004633          -0.033259   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "34         0.032013  \n",
      "Epoch 00034: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch 00034: reducing learning rate of group 0 to 4.8828e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "35  1700.0        0.0  42.502171   5.623451    1.97818          -0.035116   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "35         0.034462  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "36  1750.0        0.0  43.229166   5.420707   1.914783          -0.033432   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "36         0.032866  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "37  1800.0        0.0  43.652344   5.732515   1.954877          -0.034195   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "37         0.033596  \n",
      "Epoch 00037: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch 00037: reducing learning rate of group 0 to 2.4414e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "38  1850.0        0.0  44.238281   5.531775   1.902605          -0.033381   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "38         0.033044  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "39  1900.0        0.0  43.500435   5.453386   1.907853          -0.033256   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "39         0.032931  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "40  1950.0        0.0  43.012154   5.529608   1.939964          -0.033214   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "40         0.032891  \n",
      "Epoch 00040: reducing learning rate of group 0 to 1.9531e-06.\n",
      "Epoch 00040: reducing learning rate of group 0 to 1.2207e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "41  2000.0        0.0  43.771702   5.598898   1.937828          -0.033558   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "41         0.033387  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "42  2050.0        0.0  43.967015   5.580464   1.924566          -0.033291   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "42         0.033124  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "43  2100.0        0.0   43.60894   5.629607    1.93556          -0.033431   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "43         0.033278  \n",
      "Epoch 00043: reducing learning rate of group 0 to 9.7656e-07.\n",
      "Epoch 00043: reducing learning rate of group 0 to 6.1035e-08.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "44  2150.0        0.0  44.010416   5.559679   1.916556          -0.033372   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "44         0.033274  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "45  2200.0        0.0  44.292533   5.517224   1.906051           -0.03308   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "45         0.033004  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "46  2250.0        0.0  43.901908    5.55507    1.91591          -0.032486   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "46         0.032388  \n",
      "Epoch 00046: reducing learning rate of group 0 to 4.8828e-07.\n",
      "Epoch 00046: reducing learning rate of group 0 to 3.0518e-08.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "47  2300.0        0.0  44.010416   5.573493   1.919688          -0.033036   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "47         0.032996  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "48  2350.0        0.0  44.042969   5.573069   1.918091          -0.032857   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "48         0.032814  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "49  2400.0        0.0  43.869358    5.59627   1.926032          -0.033113   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "49         0.033067  \n",
      "Epoch 00049: reducing learning rate of group 0 to 2.4414e-07.\n",
      "Epoch 00049: reducing learning rate of group 0 to 1.5259e-08.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "50  2450.0        0.0  44.097221    5.57284   1.916997          -0.033184   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "50         0.033161  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "51  2500.0        0.0  44.097221   5.561819   1.915345          -0.032857   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "51         0.032836  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "52  2550.0        0.0  43.967015   5.585327   1.921725          -0.033351   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "52         0.033331  \n",
      "Epoch 00052: reducing learning rate of group 0 to 1.2207e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "53  2600.0        0.0  43.901908   5.608103   1.927014          -0.032103   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "53         0.032092  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "54  2650.0        0.0  43.912759    5.60431   1.926337          -0.032621   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "54          0.03261  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "55  2700.0        0.0  43.988717   5.603992   1.924422          -0.032743   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "55         0.032732  \n",
      "Epoch 00055: reducing learning rate of group 0 to 6.1035e-08.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "56  2750.0        0.0  43.956164   5.597618   1.923337          -0.032251   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "56         0.032246  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "57  2800.0        0.0  43.977866   5.596749   1.922406          -0.032384   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "57         0.032379  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "58  2850.0        0.0  43.967015   5.602063   1.924603          -0.034125   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "58         0.034119  \n",
      "Epoch 00058: reducing learning rate of group 0 to 3.0518e-08.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "59  2900.0        0.0  43.934461   5.603891   1.925205           -0.03235   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "59         0.032347  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "60  2950.0        0.0  43.945312   5.606519   1.926102          -0.032928   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "60         0.032925  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "61  3000.0        0.0  43.945312   5.611973   1.927362          -0.031705   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "61         0.031703  \n",
      "Epoch 00061: reducing learning rate of group 0 to 1.5259e-08.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "62  3050.0        0.0  43.934461   5.612578   1.927511          -0.032801   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "62         0.032801  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "63  3100.0        0.0  43.901908   5.614622   1.927957          -0.032384   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "63         0.032383  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "64  3150.0        0.0  43.912759   5.612878   1.927481          -0.032495   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "64         0.032494  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "65  3200.0        0.0  43.912759   5.612245   1.927298          -0.032732   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "65         0.032731  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "66  3250.0        0.0   43.92361   5.612521   1.927399          -0.032465   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "66         0.032464  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "67  3300.0        0.0   43.92361   5.612239   1.927277          -0.032871   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "67          0.03287  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "68  3350.0        0.0  43.912759   5.611812   1.927244          -0.033091   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "68         0.033091  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "69  3400.0        0.0  43.912759   5.612067     1.9274          -0.032199   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "69         0.032198  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "70  3450.0        0.0   43.92361   5.612945   1.927532          -0.032582   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "70         0.032581  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "71  3500.0        0.0  43.912759   5.610461   1.926803           -0.03331   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "71         0.033302  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "72  3550.0        0.0  43.912759   5.610585   1.927011          -0.032167   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "72         0.032166  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "73  3600.0        0.0  43.912759   5.609135   1.926671          -0.033149   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "73         0.033148  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "74  3650.0        0.0  43.912759   5.609172   1.926723          -0.033844   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "74         0.033843  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "75  3700.0        0.0   43.92361    5.60646   1.925782          -0.032983   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "75         0.032982  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "76  3750.0        0.0  43.934461   5.607447   1.925864          -0.033281   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "76          0.03328  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "77  3800.0        0.0   43.92361   5.608153   1.926234           -0.03376   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "77         0.033759  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "78  3850.0        0.0  43.934461   5.608449   1.926296          -0.032902   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "78         0.032901  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "79  3900.0        0.0  43.945312   5.608001   1.926305          -0.032902   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "79         0.032901  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "80  3950.0        0.0   43.92361   5.604889   1.925385           -0.03308   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "80         0.033079  \n"
     ]
    }
   ],
   "source": [
    "history_forget = [evaluate(student, forget_valid_dl, device = device)]\n",
    "AccForget = history_forget[0][\"Acc\"]*100\n",
    "ErrForget = history_forget[0][\"Loss\"]\n",
    "\n",
    "history_retain = [evaluate(student, retain_valid_dl, device = device)]\n",
    "AccRetain = history_retain[0][\"Acc\"]*100\n",
    "ErrRetain = history_retain[0][\"Loss\"]\n",
    "\n",
    "df = pd.DataFrame(columns = [\"Epochs\", \"AccForget\", \"AccRetain\", \"ErrForget\", \"ErrRetain\", \"MeanGeneratorLoss\", \"MeanStudentLoss\"])\n",
    "df = df._append({\"Epochs\":0, \"AccForget\":AccForget, \"AccRetain\":AccRetain, \"ErrForget\":ErrForget,\n",
    "                \"ErrRetain\":ErrRetain, \"MeanGeneratorLoss\":None, \"MeanStudentLoss\":None}, ignore_index = True)\n",
    "\n",
    "# saving the generator\n",
    "torch.save(generator.state_dict(), os.path.join(generator_path, str(0) + \".pt\"))\n",
    "\n",
    "# saving the student\n",
    "torch.save(student.state_dict(), os.path.join(student_path, str(0) + \".pt\"))\n",
    "\n",
    "while n_pseudo_batches < total_n_pseudo_batches:\n",
    "    x_pseudo = generator.__next__()\n",
    "    preds, *_ = model(x_pseudo)\n",
    "\n",
    "    # Threshold Criteria\n",
    "    mask = (torch.softmax(preds.detach(), dim=1)[:, 0] <= threshold)\n",
    "\n",
    "    # Entropy Criteria\n",
    "    ENTROPY_THRESH = 0.75\n",
    "    for ix, p in enumerate(preds):\n",
    "      if get_entropy(p) > ENTROPY_THRESH:\n",
    "        mask[ix] = False\n",
    "\n",
    "    x_pseudo = x_pseudo[mask]\n",
    "    if x_pseudo.size(0) == 0:\n",
    "        zero_count += 1\n",
    "        if zero_count > 100:\n",
    "            print(\"Generator Stopped Producing datapoints corresponding to retain classes.\")\n",
    "            print(\"Resetting the generator to previous checkpoint\")\n",
    "            generator.load_state_dict(torch.load(os.path.join(generator_path, str(((n_pseudo_batches//50)-1)*50) + \".pt\")))\n",
    "        continue\n",
    "    else:\n",
    "        zero_count = 0\n",
    "\n",
    "    ## Take n_generator_iter steps on generator\n",
    "    if idx_pseudo % n_repeat_batch < n_generator_iter:\n",
    "        student_logits, *student_activations = student(x_pseudo)\n",
    "        teacher_logits, *teacher_activations = model(x_pseudo)\n",
    "        generator_total_loss = KT_loss_generator(student_logits, teacher_logits, KL_temperature=KL_temperature)\n",
    "\n",
    "        optimizer_generator.zero_grad()\n",
    "        generator_total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(generator.parameters(), 5)\n",
    "        optimizer_generator.step()\n",
    "        running_gen_loss.append(generator_total_loss.cpu().detach())\n",
    "\n",
    "\n",
    "    elif idx_pseudo % n_repeat_batch < (n_generator_iter + n_student_iter):\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_logits, *teacher_activations = model(x_pseudo)\n",
    "\n",
    "        student_logits, *student_activations = student(x_pseudo)\n",
    "        student_total_loss = KT_loss_student(student_logits, student_activations,\n",
    "                                             teacher_logits, teacher_activations,\n",
    "                                             KL_temperature=KL_temperature, AT_beta = AT_beta)\n",
    "\n",
    "        optimizer_student.zero_grad()\n",
    "        student_total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(student.parameters(), 5)\n",
    "        optimizer_student.step()\n",
    "        running_stu_loss.append(student_total_loss.cpu().detach())\n",
    "\n",
    "    if (idx_pseudo + 1) % n_repeat_batch == 0:\n",
    "        if((n_pseudo_batches)% 50 == 0):\n",
    "            MeanGLoss = np.mean(running_gen_loss)\n",
    "            running_gen_loss = []\n",
    "            MeanSLoss = np.mean(running_stu_loss)\n",
    "            running_stu_loss = []\n",
    "\n",
    "            history_forget = [evaluate(student, forget_valid_dl, device = device)]\n",
    "            AccForget = history_forget[0][\"Acc\"]*100\n",
    "            ErrForget = history_forget[0][\"Loss\"]\n",
    "\n",
    "            history_retain = [evaluate(student, retain_valid_dl, device = device)]\n",
    "            AccRetain = history_retain[0][\"Acc\"]*100\n",
    "            ErrRetain = history_retain[0][\"Loss\"]\n",
    "\n",
    "            df = df._append({\"Epochs\":n_pseudo_batches, \"AccForget\":AccForget, \"AccRetain\":AccRetain, \"ErrForget\":ErrForget,\n",
    "                            \"ErrRetain\":ErrRetain, \"MeanGeneratorLoss\":MeanGLoss, \"MeanStudentLoss\":MeanSLoss}, ignore_index = True)\n",
    "            print(df.iloc[-1:])\n",
    "            scheduler_student.step(history_retain[0][\"Loss\"])\n",
    "            scheduler_generator.step(history[0][\"Loss\"])\n",
    "\n",
    "            # saving the generator\n",
    "            torch.save(generator.state_dict(), os.path.join(generator_path, str(n_pseudo_batches) + \".pt\"))\n",
    "\n",
    "            # saving the student\n",
    "            torch.save(student.state_dict(), os.path.join(student_path, str(n_pseudo_batches) + \".pt\"))\n",
    "\n",
    "\n",
    "        n_pseudo_batches += 1\n",
    "\n",
    "    idx_pseudo += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b58e2e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T23:11:08.505311Z",
     "iopub.status.busy": "2024-04-15T23:11:08.504954Z",
     "iopub.status.idle": "2024-04-15T23:11:08.523560Z",
     "shell.execute_reply": "2024-04-15T23:11:08.522636Z"
    },
    "id": "sAf-ZaYDEiLI",
    "papermill": {
     "duration": 0.041457,
     "end_time": "2024-04-15T23:11:08.525625",
     "exception": false,
     "start_time": "2024-04-15T23:11:08.484168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epochs</th>\n",
       "      <th>AccForget</th>\n",
       "      <th>AccRetain</th>\n",
       "      <th>ErrForget</th>\n",
       "      <th>ErrRetain</th>\n",
       "      <th>MeanGeneratorLoss</th>\n",
       "      <th>MeanStudentLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.802952</td>\n",
       "      <td>7.088564</td>\n",
       "      <td>2.360746</td>\n",
       "      <td>-0.056049</td>\n",
       "      <td>0.045797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.819877</td>\n",
       "      <td>4.425354</td>\n",
       "      <td>2.063575</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>0.041018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>550.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.747829</td>\n",
       "      <td>4.920764</td>\n",
       "      <td>2.050687</td>\n",
       "      <td>-0.057987</td>\n",
       "      <td>0.040448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.886283</td>\n",
       "      <td>6.899304</td>\n",
       "      <td>2.477624</td>\n",
       "      <td>-0.051221</td>\n",
       "      <td>0.043765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.004342</td>\n",
       "      <td>4.918982</td>\n",
       "      <td>2.060542</td>\n",
       "      <td>-0.049774</td>\n",
       "      <td>0.040235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.384548</td>\n",
       "      <td>4.884907</td>\n",
       "      <td>1.966202</td>\n",
       "      <td>-0.049869</td>\n",
       "      <td>0.039687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.387586</td>\n",
       "      <td>5.533535</td>\n",
       "      <td>2.056223</td>\n",
       "      <td>-0.045524</td>\n",
       "      <td>0.040228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.221789</td>\n",
       "      <td>4.561756</td>\n",
       "      <td>1.837064</td>\n",
       "      <td>-0.044719</td>\n",
       "      <td>0.038230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.950086</td>\n",
       "      <td>5.598623</td>\n",
       "      <td>2.075523</td>\n",
       "      <td>-0.043932</td>\n",
       "      <td>0.037310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.534289</td>\n",
       "      <td>5.328032</td>\n",
       "      <td>2.004816</td>\n",
       "      <td>-0.043826</td>\n",
       "      <td>0.037045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
       "10   450.0        0.0  25.802952   7.088564   2.360746          -0.056049   \n",
       "11   500.0        0.0  34.819877   4.425354   2.063575          -0.057182   \n",
       "12   550.0        0.0  38.747829   4.920764   2.050687          -0.057987   \n",
       "13   600.0        0.0  27.886283   6.899304   2.477624          -0.051221   \n",
       "14   650.0        0.0  35.004342   4.918982   2.060542          -0.049774   \n",
       "15   700.0        0.0  41.384548   4.884907   1.966202          -0.049869   \n",
       "16   750.0        0.0  33.387586   5.533535   2.056223          -0.045524   \n",
       "17   800.0        0.0  41.221789   4.561756   1.837064          -0.044719   \n",
       "18   850.0        0.0  34.950086   5.598623   2.075523          -0.043932   \n",
       "19   900.0        0.0  36.534289   5.328032   2.004816          -0.043826   \n",
       "\n",
       "    MeanStudentLoss  \n",
       "10         0.045797  \n",
       "11         0.041018  \n",
       "12         0.040448  \n",
       "13         0.043765  \n",
       "14         0.040235  \n",
       "15         0.039687  \n",
       "16         0.040228  \n",
       "17         0.038230  \n",
       "18         0.037310  \n",
       "19         0.037045  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8539c16f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T23:11:08.567558Z",
     "iopub.status.busy": "2024-04-15T23:11:08.566740Z",
     "iopub.status.idle": "2024-04-15T23:11:08.576424Z",
     "shell.execute_reply": "2024-04-15T23:11:08.575687Z"
    },
    "id": "0SVUfjiWEitM",
    "papermill": {
     "duration": 0.032412,
     "end_time": "2024-04-15T23:11:08.578303",
     "exception": false,
     "start_time": "2024-04-15T23:11:08.545891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"MNIST_ALLCNN.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be606c58",
   "metadata": {
    "id": "VdoxXEA3V10E",
    "papermill": {
     "duration": 0.019674,
     "end_time": "2024-04-15T23:11:08.617974",
     "exception": false,
     "start_time": "2024-04-15T23:11:08.598300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11745.238093,
   "end_time": "2024-04-15T23:11:11.739141",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-15T19:55:26.501048",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
