{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af239178",
   "metadata": {
    "id": "K7GwEjnhDPqh",
    "papermill": {
     "duration": 0.009515,
     "end_time": "2024-04-12T18:36:38.385319",
     "exception": false,
     "start_time": "2024-04-12T18:36:38.375804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c34f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:36:38.405029Z",
     "iopub.status.busy": "2024-04-12T18:36:38.404724Z",
     "iopub.status.idle": "2024-04-12T18:36:41.992109Z",
     "shell.execute_reply": "2024-04-12T18:36:41.991347Z"
    },
    "id": "LJrmlufaDRtm",
    "papermill": {
     "duration": 3.600074,
     "end_time": "2024-04-12T18:36:41.994469",
     "exception": false,
     "start_time": "2024-04-12T18:36:38.394395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ConvStandard(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=None, output_padding=0, w_sig =\\\n",
    "                 np.sqrt(1.0)):\n",
    "        super(ConvStandard, self).__init__(in_channels, out_channels,kernel_size)\n",
    "        self.in_channels=in_channels\n",
    "        self.out_channels=out_channels\n",
    "        self.kernel_size=kernel_size\n",
    "        self.stride=stride\n",
    "        self.padding=padding\n",
    "        self.w_sig = w_sig\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.normal_(self.weight, mean=0, std=self.w_sig/(self.in_channels*np.prod(self.kernel_size)))\n",
    "        if self.bias is not None:\n",
    "            torch.nn.init.normal_(self.bias, mean=0, std=0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.conv2d(input,self.weight,self.bias,self.stride,self.padding)\n",
    "\n",
    "class Conv(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=None, output_padding=0,\n",
    "                 activation_fn=nn.ReLU, batch_norm=True, transpose=False):\n",
    "        if padding is None:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        model = []\n",
    "        if not transpose:\n",
    "#             model += [ConvStandard(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "#                                 )]\n",
    "            model += [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                bias=not batch_norm)]\n",
    "        else:\n",
    "            model += [nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding,\n",
    "                                         output_padding=output_padding, bias=not batch_norm)]\n",
    "        if batch_norm:\n",
    "            model += [nn.BatchNorm2d(out_channels, affine=True)]\n",
    "        model += [activation_fn()]\n",
    "        super(Conv, self).__init__(*model)\n",
    "\n",
    "class AllCNN(nn.Module):\n",
    "    def __init__(self, filters_percentage=1., n_channels=3, num_classes=10, dropout=False, batch_norm=True):\n",
    "        super(AllCNN, self).__init__()\n",
    "        n_filter1 = int(96 * filters_percentage)\n",
    "        n_filter2 = int(192 * filters_percentage)\n",
    "\n",
    "        self.conv1 = Conv(n_channels, n_filter1, kernel_size=3, batch_norm=batch_norm)\n",
    "        self.conv2 = Conv(n_filter1, n_filter1, kernel_size=3, batch_norm=batch_norm)\n",
    "        self.conv3 = Conv(n_filter1, n_filter2, kernel_size=3, stride=2, padding=1, batch_norm=batch_norm)\n",
    "\n",
    "        self.dropout1 = self.features = nn.Sequential(nn.Dropout(inplace=True) if dropout else Identity())\n",
    "\n",
    "        self.conv4 = Conv(n_filter2, n_filter2, kernel_size=3, stride=1, batch_norm=batch_norm)\n",
    "        self.conv5 = Conv(n_filter2, n_filter2, kernel_size=3, stride=1, batch_norm=batch_norm)\n",
    "        self.conv6 = Conv(n_filter2, n_filter2, kernel_size=3, stride=2, padding=1, batch_norm=batch_norm)\n",
    "\n",
    "        self.dropout2 = self.features = nn.Sequential(nn.Dropout(inplace=True) if dropout else Identity())\n",
    "\n",
    "        self.conv7 = Conv(n_filter2, n_filter2, kernel_size=3, stride=1, batch_norm=batch_norm)\n",
    "        self.conv8 = Conv(n_filter2, n_filter2, kernel_size=1, stride=1, batch_norm=batch_norm)\n",
    "        if n_channels == 3:\n",
    "            self.pool = nn.AvgPool2d(8)\n",
    "        elif n_channels == 1:\n",
    "            self.pool = nn.AvgPool2d(7)\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_filter2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        actv1 = out\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        actv2 = out\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        actv3 = out\n",
    "\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        out = self.conv4(out)\n",
    "        actv4 = out\n",
    "\n",
    "        out = self.conv5(out)\n",
    "        actv5 = out\n",
    "\n",
    "        out = self.conv6(out)\n",
    "        actv6 = out\n",
    "\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        out = self.conv7(out)\n",
    "        actv7 = out\n",
    "\n",
    "        out = self.conv8(out)\n",
    "        actv8 = out\n",
    "\n",
    "        out = self.pool(out)\n",
    "\n",
    "        out = self.flatten(out)\n",
    "\n",
    "        out = self.classifier(out)\n",
    "\n",
    "        return out, actv1, actv2, actv3, actv4, actv5, actv6, actv7, actv8\n",
    "\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(View, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.view(self.size)\n",
    "\n",
    "\n",
    "class LeNet32(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(LeNet32, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            View((-1, 16*5*5)),\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, n_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x, true_labels=None):\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if idx == 0:\n",
    "                activation1 = x\n",
    "            if idx == 3:\n",
    "                activation2 = x\n",
    "\n",
    "        return x, activation1, activation2\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual block as defined by He et al.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_res1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                                   padding=padding, stride=stride, bias=False)\n",
    "        self.conv_res1_bn = nn.BatchNorm2d(num_features=out_channels, momentum=0.9)\n",
    "        self.conv_res2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                                   padding=padding, bias=False)\n",
    "        self.conv_res2_bn = nn.BatchNorm2d(num_features=out_channels, momentum=0.9)\n",
    "\n",
    "        if stride != 1:\n",
    "            # in case stride is not set to 1, we need to downsample the residual so that\n",
    "            # the dimensions are the same when we add them together\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(num_features=out_channels, momentum=0.9)\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.relu(self.conv_res1_bn(self.conv_res1(x)))\n",
    "        out = self.conv_res2_bn(self.conv_res2(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(residual)\n",
    "\n",
    "        out = self.relu(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    \"\"\"\n",
    "    A Residual network.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=64, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=128, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            ResidualBlock(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=256, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=256, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            ResidualBlock(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(in_features=1024, out_features=10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for idx, layer in enumerate(self.conv):\n",
    "            x = layer(x)\n",
    "            if idx == 0:\n",
    "                activation1 = x\n",
    "            if idx == 3:\n",
    "                activation2 = x\n",
    "            if idx == 8:\n",
    "                activation3 = x\n",
    "            if idx == 12:\n",
    "                activation4 = x\n",
    "\n",
    "        x = x.view(-1, x.shape[1] * x.shape[2] * x.shape[3])\n",
    "        x = self.fc(x)\n",
    "        return x, activation1, activation2, activation3, activation4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890fdda1",
   "metadata": {
    "id": "dQOLxw4aDU6g",
    "papermill": {
     "duration": 0.008832,
     "end_time": "2024-04-12T18:36:42.012659",
     "exception": false,
     "start_time": "2024-04-12T18:36:42.003827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abde125a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:36:42.032353Z",
     "iopub.status.busy": "2024-04-12T18:36:42.031637Z",
     "iopub.status.idle": "2024-04-12T18:36:42.050856Z",
     "shell.execute_reply": "2024-04-12T18:36:42.050018Z"
    },
    "id": "wkiAg4CNDYFg",
    "papermill": {
     "duration": 0.031168,
     "end_time": "2024-04-12T18:36:42.052771",
     "exception": false,
     "start_time": "2024-04-12T18:36:42.021603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def training_step(model, batch, device):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    out, *_ = model(images)                  # Generate predictions\n",
    "    loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "    return loss\n",
    "\n",
    "def validation_step(model, batch, device):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    out, *_ = model(images)                    # Generate predictions\n",
    "    loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "    acc = accuracy(out, labels)           # Calculate accuracy\n",
    "    return {'Loss': loss.detach(), 'Acc': acc}\n",
    "\n",
    "def validation_epoch_end(model, outputs):\n",
    "    batch_losses = [x['Loss'] for x in outputs]\n",
    "    epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "    batch_accs = [x['Acc'] for x in outputs]\n",
    "    epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "    return {'Loss': epoch_loss.item(), 'Acc': epoch_acc.item()}\n",
    "\n",
    "def epoch_end(model, epoch, result):\n",
    "    print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "        epoch, result['lrs'][-1], result['train_loss'], result['Loss'], result['Acc']))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    outputs = [validation_step(model, batch, device) for batch in val_loader]\n",
    "    return validation_epoch_end(model, outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD, device='cuda'):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = training_step(model, batch, device)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            if grad_clip:\n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            lrs.append(get_lr(optimizer))\n",
    "\n",
    "\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader, device)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        epoch_end(model, epoch, result)\n",
    "        history.append(result)\n",
    "        sched.step(result['Loss'])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1079ed",
   "metadata": {
    "id": "bnP_tORZDcPY",
    "papermill": {
     "duration": 0.008714,
     "end_time": "2024-04-12T18:36:42.070329",
     "exception": false,
     "start_time": "2024-04-12T18:36:42.061615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3bb1124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:36:42.090080Z",
     "iopub.status.busy": "2024-04-12T18:36:42.089794Z",
     "iopub.status.idle": "2024-04-12T18:36:44.934095Z",
     "shell.execute_reply": "2024-04-12T18:36:44.933342Z"
    },
    "id": "L-dkO84YDdQD",
    "papermill": {
     "duration": 2.857516,
     "end_time": "2024-04-12T18:36:44.936613",
     "exception": false,
     "start_time": "2024-04-12T18:36:42.079097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as tt\n",
    "import tarfile\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.utils import download_url\n",
    "\n",
    "\n",
    "def cifar10(root = './'):\n",
    "    transform = tt.Compose([\n",
    "        tt.ToTensor(),\n",
    "        tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
    "    download_url(dataset_url, '.')\n",
    "\n",
    "    # Extract from archive\n",
    "    with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
    "        tar.extractall(path='./data')\n",
    "\n",
    "    # Look into the data directory\n",
    "    data_dir = os.path.join(root, 'data/cifar10')\n",
    "    #print(os.listdir(data_dir))\n",
    "    #classes = os.listdir(data_dir + \"/train\")\n",
    "\n",
    "    #train_ds = torchvision.datasets.CIFAR10(root='./', train=True, download=True, transform=transform)\n",
    "    #valid_ds = torchvision.datasets.CIFAR10(root='./', train=False, download=True, transform=transform)\n",
    "    train_ds = ImageFolder(data_dir+'/train', transform)\n",
    "    valid_ds = ImageFolder(data_dir+'/test', transform)\n",
    "    return train_ds, valid_ds\n",
    "\n",
    "def svhn(root = './'):\n",
    "    transform = tt.Compose([\n",
    "        tt.ToTensor(),\n",
    "        tt.Normalize((0.4376821, 0.4437697, 0.47280442), (0.19803012, 0.20101562, 0.19703614))\n",
    "    ])\n",
    "\n",
    "    train_ds = torchvision.datasets.SVHN(root='./', train=True, download=True, transform=transform)\n",
    "    valid_ds = torchvision.datasets.SVHN(root='./', train=False, download=True, transform=transform)\n",
    "\n",
    "    return train_ds, valid_ds\n",
    "\n",
    "def mnist(root = './'):\n",
    "    transform = tt.Compose([\n",
    "        tt.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_ds = torchvision.datasets.MNIST(root='./', train=True, download=True, transform=transform)\n",
    "    valid_ds = torchvision.datasets.MNIST(root='./', train=False, download=True, transform=transform)\n",
    "\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835ad71",
   "metadata": {
    "id": "lBeno57iDd6X",
    "papermill": {
     "duration": 0.008743,
     "end_time": "2024-04-12T18:36:44.954687",
     "exception": false,
     "start_time": "2024-04-12T18:36:44.945944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metric.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df89b15e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:36:44.974087Z",
     "iopub.status.busy": "2024-04-12T18:36:44.973707Z",
     "iopub.status.idle": "2024-04-12T18:36:46.302156Z",
     "shell.execute_reply": "2024-04-12T18:36:46.301411Z"
    },
    "id": "PZNxNtbqDg93",
    "papermill": {
     "duration": 1.340869,
     "end_time": "2024-04-12T18:36:46.304380",
     "exception": false,
     "start_time": "2024-04-12T18:36:44.963511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def entropy(p, dim = -1, keepdim = False):\n",
    "    return -torch.where(p > 0, p * p.log(), p.new([0.0])).sum(dim=dim, keepdim=keepdim)\n",
    "\n",
    "def collect_prob(data_loader, model):\n",
    "    data_loader = torch.utils.data.DataLoader(data_loader.dataset, batch_size=1, shuffle=False, num_workers = 32, prefetch_factor = 10)\n",
    "    prob = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = [tensor.to(next(model.parameters()).device) for tensor in batch]\n",
    "            data, _, target = batch\n",
    "            output = model(data)\n",
    "            prob.append(F.softmax(output, dim=-1).data)\n",
    "    return torch.cat(prob)\n",
    "\n",
    "def get_membership_attack_data(retain_loader, forget_loader, test_loader, model):\n",
    "    retain_prob = collect_prob(retain_loader, model)\n",
    "    forget_prob = collect_prob(forget_loader, model)\n",
    "    test_prob = collect_prob(test_loader, model)\n",
    "\n",
    "    X_r = torch.cat([entropy(retain_prob), entropy(test_prob)]).cpu().numpy().reshape(-1, 1)\n",
    "    Y_r = np.concatenate([np.ones(len(retain_prob)), np.zeros(len(test_prob))])\n",
    "\n",
    "    X_f = entropy(forget_prob).cpu().numpy().reshape(-1, 1)\n",
    "    Y_f = np.concatenate([np.ones(len(forget_prob))])\n",
    "    return X_f, Y_f, X_r, Y_r\n",
    "\n",
    "def get_membership_attack_prob(retain_loader, forget_loader, test_loader, model):\n",
    "    X_f, Y_f, X_r, Y_r = get_membership_attack_data(retain_loader, forget_loader, test_loader, model)\n",
    "    clf = SVC(C=3,gamma='auto',kernel='rbf')\n",
    "    #clf = LogisticRegression(class_weight='balanced',solver='lbfgs',multi_class='multinomial')\n",
    "    clf.fit(X_r, Y_r)\n",
    "    results = clf.predict(X_f)\n",
    "    return results.mean()\n",
    "\n",
    "def relearn_time(model, train_loader, valid_loader, reqAcc, lr):\n",
    "    # measuring relearn time for gold standard model\n",
    "    rltime = 0\n",
    "    curr_Acc = 0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    # we will try the relearning step till 4 epochs.\n",
    "    for epoch in range(10):\n",
    "\n",
    "        for batch in train_loader:\n",
    "            model.train()\n",
    "            loss = training_step(model, batch)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            history = [evaluate(model, valid_dl)]\n",
    "            curr_Acc = history[0][\"Acc\"]*100\n",
    "            print(curr_Acc, sep=',')\n",
    "\n",
    "\n",
    "\n",
    "            rltime += 1\n",
    "            if(curr_Acc >= reqAcc):\n",
    "                break\n",
    "\n",
    "        if(curr_Acc >= reqAcc):\n",
    "            break\n",
    "    return rltime\n",
    "\n",
    "def ain(full_model, model, gold_model, train_data, val_retain, val_forget,\n",
    "                  batch_size = 256, error_range = 0.05, lr = 0.001):\n",
    "    # measuring performance of fully trained model on forget class\n",
    "    forget_valid_dl = DataLoader(val_forget, batch_size)\n",
    "    history = [evaluate(full_model, forget_valid_dl)]\n",
    "    AccForget = history[0][\"Acc\"]*100\n",
    "\n",
    "    print(\"Accuracy of fully trained model on forget set is: {}\".format(AccForget))\n",
    "\n",
    "    retain_valid_dl = DataLoader(val_retain, batch_size)\n",
    "    history = [evaluate(full_model, retain_valid_dl)]\n",
    "    AccRetain = history[0][\"Acc\"]*100\n",
    "\n",
    "    print(\"Accuracy of fully trained model on retain set is: {}\".format(AccRetain))\n",
    "\n",
    "    history = [evaluate(model, forget_valid_dl)]\n",
    "    AccForget_Fmodel = history[0][\"Acc\"]*100\n",
    "\n",
    "    print(\"Accuracy of forget model on forget set is: {}\".format(AccForget_Fmodel))\n",
    "\n",
    "    history = [evaluate(model, retain_valid_dl)]\n",
    "    AccRetain_Fmodel = history[0][\"Acc\"]*100\n",
    "\n",
    "    print(\"Accuracy of forget model on retain set is: {}\".format(AccRetain_Fmodel))\n",
    "\n",
    "    history = [evaluate(gold_model, forget_valid_dl)]\n",
    "    AccForget_Gmodel = history[0][\"Acc\"]*100\n",
    "\n",
    "    print(\"Accuracy of gold model on forget set is: {}\".format(AccForget_Gmodel))\n",
    "\n",
    "    history = [evaluate(gold_model, retain_valid_dl)]\n",
    "    AccRetain_Gmodel = history[0][\"Acc\"]*100\n",
    "\n",
    "    print(\"Accuracy of gold model on retain set is: {}\".format(AccRetain_Gmodel))\n",
    "\n",
    "    reqAccF = (1-error_range)*AccForget\n",
    "\n",
    "    print(\"Desired Accuracy for retrain time with error range {} is {}\".format(error_range, reqAccF))\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size, shuffle = True)\n",
    "    valid_loader = DataLoader(val_forget, batch_size)\n",
    "    rltime_gold = relearn_time(model = gold_model, train_loader = train_loader, valid_loader = valid_loader,\n",
    "                               reqAcc = reqAccF,  lr = lr)\n",
    "\n",
    "    print(\"Relearning time for Gold Standard Model is {}\".format(rltime_gold))\n",
    "\n",
    "    rltime_forget = relearn_time(model = model, train_loader = train_loader, valid_loader = valid_loader,\n",
    "                               reqAcc = reqAccF, lr = lr)\n",
    "\n",
    "    print(\"Relearning time for Forget Model is {}\".format(rltime_forget))\n",
    "\n",
    "    rl_coeff = rltime_forget/rltime_gold\n",
    "    print(\"AIN = {}\".format(rl_coeff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2ac66f",
   "metadata": {
    "id": "tvm7S3SVDhpf",
    "papermill": {
     "duration": 0.008996,
     "end_time": "2024-04-12T18:36:46.322557",
     "exception": false,
     "start_time": "2024-04-12T18:36:46.313561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Unlearn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec856520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:36:46.342064Z",
     "iopub.status.busy": "2024-04-12T18:36:46.341651Z",
     "iopub.status.idle": "2024-04-12T18:36:46.364007Z",
     "shell.execute_reply": "2024-04-12T18:36:46.363207Z"
    },
    "id": "-C3moEJZDpXn",
    "papermill": {
     "duration": 0.034349,
     "end_time": "2024-04-12T18:36:46.365893",
     "exception": false,
     "start_time": "2024-04-12T18:36:46.331544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def attention(x):\n",
    "        \"\"\"\n",
    "        Taken from https://github.com/szagoruyko/attention-transfer\n",
    "        :param x = activations\n",
    "        \"\"\"\n",
    "        return F.normalize(x.pow(2).mean(1).view(x.size(0), -1))\n",
    "\n",
    "\n",
    "def attention_diff(x, y):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/szagoruyko/attention-transfer\n",
    "    :param x = activations\n",
    "    :param y = activations\n",
    "    \"\"\"\n",
    "    return (attention(x) - attention(y)).pow(2).mean()\n",
    "\n",
    "\n",
    "def divergence(student_logits, teacher_logits, KL_temperature):\n",
    "    divergence = F.kl_div(F.log_softmax(student_logits / KL_temperature, dim=1), F.softmax(teacher_logits / KL_temperature, dim=1))  # forward KL\n",
    "\n",
    "    return divergence\n",
    "\n",
    "\n",
    "def KT_loss_generator(student_logits, teacher_logits, KL_temperature):\n",
    "\n",
    "    divergence_loss = divergence(student_logits, teacher_logits, KL_temperature)\n",
    "    total_loss = - divergence_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def KT_loss_student(student_logits, student_activations, teacher_logits, teacher_activations, KL_temperature = 1, AT_beta = 250):\n",
    "\n",
    "    divergence_loss = divergence(student_logits, teacher_logits, KL_temperature)\n",
    "    if AT_beta > 0:\n",
    "        at_loss = 0\n",
    "        for i in range(len(student_activations)):\n",
    "            at_loss = at_loss + AT_beta * attention_diff(student_activations[i], teacher_activations[i])\n",
    "    else:\n",
    "        at_loss = 0\n",
    "\n",
    "    total_loss = divergence_loss + at_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim, num_channels = 3):\n",
    "        super(Generator, self).__init__()\n",
    "        prefinal_layer = None\n",
    "        final_layer = None\n",
    "        if num_channels == 3:\n",
    "            prefinal_layer = nn.Conv2d(64, 3, 3, stride=1, padding=1)\n",
    "            final_layer = nn.BatchNorm2d(3, affine=True)\n",
    "        elif num_channels == 1:\n",
    "            prefinal_layer = nn.Conv2d(64, 1, 7, stride=1, padding=1)\n",
    "            final_layer = nn.BatchNorm2d(1, affine=True)\n",
    "        else:\n",
    "            print(f\"Generator Not Supported for {num_channels} channels\")\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(z_dim, 128 * 8**2),\n",
    "            View((-1, 128, 8, 8)),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            prefinal_layer,\n",
    "            final_layer\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.layers(z)\n",
    "\n",
    "    def print_shape(self, x):\n",
    "        \"\"\"\n",
    "        For debugging purposes\n",
    "        \"\"\"\n",
    "        act = x\n",
    "        for layer in self.layers:\n",
    "            act = layer(act)\n",
    "            print('\\n', layer, '---->', act.shape)\n",
    "\n",
    "\n",
    "class LearnableLoader(nn.Module):\n",
    "    def __init__(self, n_repeat_batch, num_channels = 3,device='cuda'):\n",
    "        \"\"\"\n",
    "        Infinite loader, which contains a learnable generator.\n",
    "        \"\"\"\n",
    "\n",
    "        super(LearnableLoader, self).__init__()\n",
    "        self.batch_size = 256\n",
    "        self.n_repeat_batch = n_repeat_batch\n",
    "        self.z_dim = 128\n",
    "        self.generator = Generator(self.z_dim, num_channels=num_channels).to(device=device)\n",
    "        self.device = device\n",
    "\n",
    "        self._running_repeat_batch_idx = 0\n",
    "        self.z = torch.randn((self.batch_size, self.z_dim)).to(device=self.device)\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._running_repeat_batch_idx == self.n_repeat_batch:\n",
    "            self.z = torch.randn((self.batch_size, self.z_dim)).to(device=self.device)\n",
    "            self._running_repeat_batch_idx = 0\n",
    "\n",
    "        images = self.generator(self.z)\n",
    "        self._running_repeat_batch_idx += 1\n",
    "        return images\n",
    "\n",
    "    def samples(self, n, grid=True):\n",
    "        \"\"\"\n",
    "        :return: if grid returns single grid image, else\n",
    "        returns n images.\n",
    "        \"\"\"\n",
    "        self.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn((n, self.z_dim)).to(device=self.device)\n",
    "            images = visualize(self.generator(z), dataset=self.dataset).cpu()\n",
    "            if grid:\n",
    "                images = make_grid(images, nrow=round(math.sqrt(n)), normalize=True)\n",
    "\n",
    "        self.generator.train()\n",
    "        return images\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7853f6",
   "metadata": {
    "id": "yywXC9m8Dwsn",
    "papermill": {
     "duration": 0.008911,
     "end_time": "2024-04-12T18:36:46.383614",
     "exception": false,
     "start_time": "2024-04-12T18:36:46.374703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f656de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:36:46.402327Z",
     "iopub.status.busy": "2024-04-12T18:36:46.402043Z",
     "iopub.status.idle": "2024-04-12T18:36:47.077673Z",
     "shell.execute_reply": "2024-04-12T18:36:47.076809Z"
    },
    "id": "_shdf4zqDx7E",
    "outputId": "f3b0ef52-6612-40ca-ecaa-9ccb12adb386",
    "papermill": {
     "duration": 0.687221,
     "end_time": "2024-04-12T18:36:47.079686",
     "exception": false,
     "start_time": "2024-04-12T18:36:46.392465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7a7ca517f690>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necessary Imports\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "659cdd94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:36:47.099412Z",
     "iopub.status.busy": "2024-04-12T18:36:47.098975Z",
     "iopub.status.idle": "2024-04-12T18:36:48.127000Z",
     "shell.execute_reply": "2024-04-12T18:36:48.125891Z"
    },
    "id": "iRqF7H5gD3de",
    "outputId": "85a85f6c-c858-4cac-82ed-56e3ec29628c",
    "papermill": {
     "duration": 1.040171,
     "end_time": "2024-04-12T18:36:48.129184",
     "exception": false,
     "start_time": "2024-04-12T18:36:47.089013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 190005672.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 51547103.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 66866722.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 8304502.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_ds, valid_ds = mnist()\n",
    "\n",
    "batch_size = 256\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=16)\n",
    "valid_dl = DataLoader(valid_ds, batch_size, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef1bc9c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:36:48.152127Z",
     "iopub.status.busy": "2024-04-12T18:36:48.151827Z",
     "iopub.status.idle": "2024-04-12T18:36:55.866666Z",
     "shell.execute_reply": "2024-04-12T18:36:55.865805Z"
    },
    "id": "ZmbnP8ozD38G",
    "papermill": {
     "duration": 7.728501,
     "end_time": "2024-04-12T18:36:55.868839",
     "exception": false,
     "start_time": "2024-04-12T18:36:48.140338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "classwise_train = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_train[i] = []\n",
    "\n",
    "for img, label in train_ds:\n",
    "    classwise_train[label].append((img, label))\n",
    "\n",
    "classwise_test = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_test[i] = []\n",
    "\n",
    "for img, label in valid_ds:\n",
    "    classwise_test[label].append((img, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a8dda0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:36:55.892154Z",
     "iopub.status.busy": "2024-04-12T18:36:55.891889Z",
     "iopub.status.idle": "2024-04-12T18:36:55.895712Z",
     "shell.execute_reply": "2024-04-12T18:36:55.894894Z"
    },
    "id": "0I3jnEXID5LW",
    "papermill": {
     "duration": 0.017344,
     "end_time": "2024-04-12T18:36:55.897545",
     "exception": false,
     "start_time": "2024-04-12T18:36:55.880201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "261c7569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:36:55.920193Z",
     "iopub.status.busy": "2024-04-12T18:36:55.919954Z",
     "iopub.status.idle": "2024-04-12T18:36:56.158352Z",
     "shell.execute_reply": "2024-04-12T18:36:56.157351Z"
    },
    "id": "sLQnr5ivD67r",
    "papermill": {
     "duration": 0.25227,
     "end_time": "2024-04-12T18:36:56.160664",
     "exception": false,
     "start_time": "2024-04-12T18:36:55.908394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AllCNN(n_channels = 1).to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7851c8ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:36:56.183349Z",
     "iopub.status.busy": "2024-04-12T18:36:56.183018Z",
     "iopub.status.idle": "2024-04-12T18:36:56.187309Z",
     "shell.execute_reply": "2024-04-12T18:36:56.186568Z"
    },
    "id": "-IDTJ9JAD8Ao",
    "papermill": {
     "duration": 0.017524,
     "end_time": "2024-04-12T18:36:56.189081",
     "exception": false,
     "start_time": "2024-04-12T18:36:56.171557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f8e3761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:36:56.211126Z",
     "iopub.status.busy": "2024-04-12T18:36:56.210865Z",
     "iopub.status.idle": "2024-04-12T18:42:28.435012Z",
     "shell.execute_reply": "2024-04-12T18:42:28.433855Z"
    },
    "id": "rjIm1PW6D9jV",
    "outputId": "285fee58-daff-44d3-b8a1-a303be48637b",
    "papermill": {
     "duration": 332.237364,
     "end_time": "2024-04-12T18:42:28.437015",
     "exception": false,
     "start_time": "2024-04-12T18:36:56.199651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.01000, train_loss: 0.2732, val_loss: 0.9030, val_acc: 0.6732\n",
      "Epoch [1], last_lr: 0.01000, train_loss: 0.0714, val_loss: 0.2150, val_acc: 0.9320\n",
      "Epoch [2], last_lr: 0.01000, train_loss: 0.0592, val_loss: 0.0930, val_acc: 0.9703\n",
      "Epoch [3], last_lr: 0.01000, train_loss: 0.0524, val_loss: 0.0640, val_acc: 0.9807\n",
      "Epoch [4], last_lr: 0.01000, train_loss: 0.0463, val_loss: 0.0949, val_acc: 0.9711\n",
      "Epoch [5], last_lr: 0.01000, train_loss: 0.0412, val_loss: 0.1680, val_acc: 0.9551\n",
      "Epoch [6], last_lr: 0.01000, train_loss: 0.0390, val_loss: 0.0366, val_acc: 0.9892\n",
      "Epoch [7], last_lr: 0.01000, train_loss: 0.0373, val_loss: 0.0527, val_acc: 0.9833\n",
      "Epoch [8], last_lr: 0.01000, train_loss: 0.0356, val_loss: 0.0414, val_acc: 0.9866\n",
      "Epoch [9], last_lr: 0.01000, train_loss: 0.0348, val_loss: 0.0417, val_acc: 0.9869\n",
      "Epoch [10], last_lr: 0.01000, train_loss: 0.0352, val_loss: 0.0357, val_acc: 0.9895\n",
      "Epoch [11], last_lr: 0.01000, train_loss: 0.0312, val_loss: 0.0335, val_acc: 0.9893\n",
      "Epoch [12], last_lr: 0.01000, train_loss: 0.0323, val_loss: 0.1818, val_acc: 0.9440\n",
      "Epoch [13], last_lr: 0.01000, train_loss: 0.0317, val_loss: 0.0682, val_acc: 0.9802\n",
      "Epoch [14], last_lr: 0.01000, train_loss: 0.0312, val_loss: 0.0585, val_acc: 0.9825\n",
      "Epoch [15], last_lr: 0.01000, train_loss: 0.0304, val_loss: 0.0430, val_acc: 0.9870\n",
      "Epoch 00016: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch [16], last_lr: 0.00500, train_loss: 0.0192, val_loss: 0.0223, val_acc: 0.9932\n",
      "Epoch [17], last_lr: 0.00500, train_loss: 0.0183, val_loss: 0.0272, val_acc: 0.9916\n",
      "Epoch [18], last_lr: 0.00500, train_loss: 0.0185, val_loss: 0.0256, val_acc: 0.9916\n",
      "Epoch [19], last_lr: 0.00500, train_loss: 0.0180, val_loss: 0.0232, val_acc: 0.9927\n",
      "Epoch [20], last_lr: 0.00500, train_loss: 0.0192, val_loss: 0.0300, val_acc: 0.9895\n",
      "Epoch 00021: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch [21], last_lr: 0.00250, train_loss: 0.0110, val_loss: 0.0166, val_acc: 0.9949\n",
      "Epoch [22], last_lr: 0.00250, train_loss: 0.0093, val_loss: 0.0154, val_acc: 0.9951\n",
      "Epoch [23], last_lr: 0.00250, train_loss: 0.0091, val_loss: 0.0204, val_acc: 0.9934\n",
      "Epoch [24], last_lr: 0.00250, train_loss: 0.0096, val_loss: 0.0203, val_acc: 0.9933\n",
      "CPU times: user 4min 43s, sys: 18.3 s, total: 5min 1s\n",
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl,\n",
    "                             grad_clip=grad_clip,\n",
    "                             weight_decay=weight_decay,\n",
    "                             opt_func=opt_func, device = device)\n",
    "torch.save(model.state_dict(), \"AllCNN_MNIST_ALL_CLASSES.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a06a82b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:42:28.464236Z",
     "iopub.status.busy": "2024-04-12T18:42:28.463579Z",
     "iopub.status.idle": "2024-04-12T18:42:29.911627Z",
     "shell.execute_reply": "2024-04-12T18:42:29.910460Z"
    },
    "id": "YNRw3ytAD_C6",
    "outputId": "276bf20c-4961-439d-e254-8dced20b7fc5",
    "papermill": {
     "duration": 1.464127,
     "end_time": "2024-04-12T18:42:29.913893",
     "exception": false,
     "start_time": "2024-04-12T18:42:28.449766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Loss': 0.02027377299964428, 'Acc': 0.9932616949081421}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"AllCNN_MNIST_ALL_CLASSES.pt\"))\n",
    "history = [evaluate(model, valid_dl, device = device)]\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a156b29",
   "metadata": {
    "id": "qq6K1RKnECal",
    "papermill": {
     "duration": 0.012594,
     "end_time": "2024-04-12T18:42:29.939963",
     "exception": false,
     "start_time": "2024-04-12T18:42:29.927369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Forgetting Class 0 using GKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcb6b1e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:42:29.966961Z",
     "iopub.status.busy": "2024-04-12T18:42:29.966628Z",
     "iopub.status.idle": "2024-04-12T18:42:29.979252Z",
     "shell.execute_reply": "2024-04-12T18:42:29.978598Z"
    },
    "id": "DoHVTWKJEAPa",
    "outputId": "90429c97-8d95-4944-ba4d-29bb30397889",
    "papermill": {
     "duration": 0.028501,
     "end_time": "2024-04-12T18:42:29.981129",
     "exception": false,
     "start_time": "2024-04-12T18:42:29.952628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the forget and retain data\n",
    "forget_valid = []\n",
    "forget_classes = [0]\n",
    "for cls in range(num_classes):\n",
    "    if cls in forget_classes:\n",
    "        for img, label in classwise_test[cls]:\n",
    "            forget_valid.append((img, label))\n",
    "\n",
    "retain_valid = []\n",
    "for cls in range(num_classes):\n",
    "    if cls not in forget_classes:\n",
    "        for img, label in classwise_test[cls]:\n",
    "            retain_valid.append((img, label))\n",
    "\n",
    "forget_valid_dl = DataLoader(forget_valid, batch_size, num_workers=3, pin_memory=True)\n",
    "\n",
    "retain_valid_dl = DataLoader(retain_valid, batch_size, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3869f4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:42:30.008667Z",
     "iopub.status.busy": "2024-04-12T18:42:30.008015Z",
     "iopub.status.idle": "2024-04-12T18:42:30.011975Z",
     "shell.execute_reply": "2024-04-12T18:42:30.011165Z"
    },
    "id": "pafNKdIsEHwA",
    "papermill": {
     "duration": 0.020055,
     "end_time": "2024-04-12T18:42:30.013801",
     "exception": false,
     "start_time": "2024-04-12T18:42:29.993746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_generator_iter = 1\n",
    "n_student_iter = 10\n",
    "n_repeat_batch = n_generator_iter + n_student_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c12f5f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:42:30.040160Z",
     "iopub.status.busy": "2024-04-12T18:42:30.039652Z",
     "iopub.status.idle": "2024-04-12T18:42:30.116983Z",
     "shell.execute_reply": "2024-04-12T18:42:30.116333Z"
    },
    "id": "f5hetsYZEITE",
    "papermill": {
     "duration": 0.092501,
     "end_time": "2024-04-12T18:42:30.118839",
     "exception": false,
     "start_time": "2024-04-12T18:42:30.026338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AllCNN(n_channels = 1).to(device = device)\n",
    "model.load_state_dict(torch.load(\"AllCNN_MNIST_ALL_CLASSES.pt\"))\n",
    "\n",
    "student = AllCNN(n_channels = 1).to(device = device)\n",
    "generator = LearnableLoader(n_repeat_batch=n_repeat_batch, num_channels = 1, device = device).to(device=device)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "scheduler_generator = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_generator,\n",
    "                                                               mode='min', factor=0.5, patience=2, verbose=True)\n",
    "optimizer_student = torch.optim.Adam(student.parameters(), lr=0.001)\n",
    "scheduler_student = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_student, \\\n",
    "                                    mode='min', factor=0.5, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "059e5d93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:42:30.145794Z",
     "iopub.status.busy": "2024-04-12T18:42:30.145528Z",
     "iopub.status.idle": "2024-04-12T18:42:31.695040Z",
     "shell.execute_reply": "2024-04-12T18:42:31.693794Z"
    },
    "id": "8Tc05Ck8EUNe",
    "outputId": "89738707-24f7-4768-eca8-fb978b705f06",
    "papermill": {
     "duration": 1.565713,
     "end_time": "2024-04-12T18:42:31.697450",
     "exception": false,
     "start_time": "2024-04-12T18:42:30.131737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Fully Trained Model on Forget Class\n",
      "Accuracy: 99.47118163108826\n",
      "Loss: 0.014611284248530865\n",
      "Performance of Fully Trained Model on Retain Class\n",
      "Accuracy: 99.27011132240295\n",
      "Loss: 0.022045528516173363\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance of Fully Trained Model on Forget Class\")\n",
    "history = [evaluate(model, forget_valid_dl, device = device)]\n",
    "print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "print(\"Loss: {}\".format(history[0][\"Loss\"]))\n",
    "\n",
    "print(\"Performance of Fully Trained Model on Retain Class\")\n",
    "history = [evaluate(model, retain_valid_dl, device = device)]\n",
    "print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "print(\"Loss: {}\".format(history[0][\"Loss\"]))\n",
    "\n",
    "\n",
    "history = [evaluate(student, forget_valid_dl, device = device)]\n",
    "AccForget = history[0][\"Acc\"]*100\n",
    "ErrForget = history[0][\"Loss\"]\n",
    "\n",
    "history = [evaluate(student, retain_valid_dl, device = device)]\n",
    "AccRetain = history[0][\"Acc\"]*100\n",
    "ErrRetain = history[0][\"Loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93dfb381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:42:31.725705Z",
     "iopub.status.busy": "2024-04-12T18:42:31.725373Z",
     "iopub.status.idle": "2024-04-12T18:42:31.731026Z",
     "shell.execute_reply": "2024-04-12T18:42:31.730330Z"
    },
    "id": "bndt1dOWEWuO",
    "papermill": {
     "duration": 0.021922,
     "end_time": "2024-04-12T18:42:31.732910",
     "exception": false,
     "start_time": "2024-04-12T18:42:31.710988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator_path = \"./ckpts/mnist_allcnn/generator\"\n",
    "student_path = \"./ckpts/mnist_allcnn/student\"\n",
    "\n",
    "os.makedirs(generator_path)\n",
    "os.makedirs(student_path)\n",
    "\n",
    "idx_pseudo = 0\n",
    "total_n_pseudo_batches = 4000\n",
    "n_pseudo_batches = 0\n",
    "running_gen_loss = []\n",
    "running_stu_loss = []\n",
    "\n",
    "threshold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "219d84dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:42:31.760385Z",
     "iopub.status.busy": "2024-04-12T18:42:31.760075Z",
     "iopub.status.idle": "2024-04-12T18:42:31.763890Z",
     "shell.execute_reply": "2024-04-12T18:42:31.763154Z"
    },
    "id": "g6jh_lEtEX7o",
    "papermill": {
     "duration": 0.01941,
     "end_time": "2024-04-12T18:42:31.765707",
     "exception": false,
     "start_time": "2024-04-12T18:42:31.746297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e525cce6",
   "metadata": {
    "id": "2wUbvWU-Ebmv",
    "papermill": {
     "duration": 0.012801,
     "end_time": "2024-04-12T18:42:31.791378",
     "exception": false,
     "start_time": "2024-04-12T18:42:31.778577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training the unlearned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad6b0198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:42:31.821840Z",
     "iopub.status.busy": "2024-04-12T18:42:31.821497Z",
     "iopub.status.idle": "2024-04-12T18:42:31.825778Z",
     "shell.execute_reply": "2024-04-12T18:42:31.824847Z"
    },
    "id": "78mefkmfEZbO",
    "papermill": {
     "duration": 0.022776,
     "end_time": "2024-04-12T18:42:31.827805",
     "exception": false,
     "start_time": "2024-04-12T18:42:31.805029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "KL_temperature = 1\n",
    "AT_beta = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8042cef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:42:31.858066Z",
     "iopub.status.busy": "2024-04-12T18:42:31.857778Z",
     "iopub.status.idle": "2024-04-12T18:42:31.862830Z",
     "shell.execute_reply": "2024-04-12T18:42:31.861915Z"
    },
    "id": "-0oe1W_gY3p8",
    "papermill": {
     "duration": 0.022662,
     "end_time": "2024-04-12T18:42:31.864916",
     "exception": false,
     "start_time": "2024-04-12T18:42:31.842254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_entropy(probs):\n",
    "      myprobs = torch.nn.functional.softmax(probs)\n",
    "      sum = 0\n",
    "      for p in myprobs:\n",
    "        sum+=float((-p) * torch.log(p))\n",
    "      return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84819ea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T18:42:31.896308Z",
     "iopub.status.busy": "2024-04-12T18:42:31.896008Z",
     "iopub.status.idle": "2024-04-12T21:29:53.117053Z",
     "shell.execute_reply": "2024-04-12T21:29:53.116067Z"
    },
    "id": "g1d2H5OiEeGW",
    "outputId": "9114a114-0ac1-4310-d194-b7206fea30dc",
    "papermill": {
     "duration": 10041.240106,
     "end_time": "2024-04-12T21:29:53.119634",
     "exception": false,
     "start_time": "2024-04-12T18:42:31.879528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "1     0.0        0.0  10.568576   2.382791   2.302812            -0.2208   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "1         7.062558  \n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "2    50.0        0.0  28.819445   4.360375   2.972248          -0.089546   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "2         1.743567  \n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "3   100.0        0.0  33.344185    4.96247   3.062082          -0.025364   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "3         0.772238  \n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "4   150.0        0.0  40.125868   3.975454   2.532236          -0.005246   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "4         0.387368  \n",
      "Epoch 00004: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00004: reducing learning rate of group 0 to 5.0000e-04.\n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "5   200.0        0.0   42.36111   2.462573   2.041227          -0.002584   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "5         0.174699  \n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "6   250.0        0.0  45.019531   2.282999   1.633212          -0.002873   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "6         0.147231  \n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "7   300.0   3.031029  48.697916   1.576319   1.289526          -0.002529   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "7         0.136733  \n",
      "Epoch 00007: reducing learning rate of group 0 to 2.5000e-04.\n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "8   350.0  69.173789     64.273    1.00093    0.82013          -0.002993   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "8         0.132709  \n",
      "   Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "9   400.0  80.032063    72.8342   0.832578   0.704911           -0.00139   \n",
      "\n",
      "   MeanStudentLoss  \n",
      "9         0.104524  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "10   450.0  85.545033  75.776184    0.77252   0.689638          -0.001833   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "10         0.106669  \n",
      "Epoch 00010: reducing learning rate of group 0 to 1.2500e-04.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "11   500.0  92.233562  83.798468   0.492956   0.472704          -0.001328   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "11         0.092433  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "12   550.0   89.18227  85.361695   0.529845   0.387618          -0.000945   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "12         0.090699  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "13   600.0  97.201133  85.693002   0.215013   0.350229          -0.001336   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "13         0.102793  \n",
      "Epoch 00013: reducing learning rate of group 0 to 6.2500e-05.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "14   650.0  92.408609  94.866902     0.3877   0.175202          -0.000959   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "14         0.092109  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "15   700.0  93.641287  97.427666    0.40089   0.115978          -0.000825   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "15         0.085356  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "16   750.0  98.140848  98.634982   0.180643   0.053242          -0.000877   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "16         0.081713  \n",
      "Epoch 00016: reducing learning rate of group 0 to 3.1250e-05.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "17   800.0  95.106131  98.431712   0.276824    0.06832          -0.001005   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "17         0.085407  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "18   850.0   96.04584  98.512733   0.225446   0.057395          -0.000656   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "18           0.0698  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "19   900.0   96.67232  98.718899   0.183967   0.042214          -0.000734   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "19         0.068694  \n",
      "Epoch 00019: reducing learning rate of group 0 to 1.5625e-05.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "20   950.0  95.106131   98.75145   0.257593   0.041107            -0.0007   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "20         0.067871  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "21  1000.0  96.554393  98.919994   0.184517   0.037058          -0.000814   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "21         0.067683  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "22  1050.0  96.066111   99.03357   0.195644   0.033892          -0.000732   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "22         0.062534  \n",
      "Epoch 00022: reducing learning rate of group 0 to 7.8125e-06.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "23  1100.0  97.355914  98.851997    0.13093    0.03583          -0.000478   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "23         0.054884  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "24  1150.0  96.945018  98.993057   0.138683   0.030879          -0.000582   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "24         0.064112  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "25  1200.0  98.140848  98.786896   0.099602   0.036884          -0.000615   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "25         0.063016  \n",
      "Epoch 00025: reducing learning rate of group 0 to 3.9063e-06.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "26  1250.0  97.416717  99.050206   0.103862   0.031657          -0.000538   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "26         0.052877  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "27  1300.0  97.827607  99.107349   0.098951   0.029561          -0.000598   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "27           0.0514  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "28  1350.0  97.416717  99.039352   0.107174   0.029368          -0.000618   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "28         0.051177  \n",
      "Epoch 00028: reducing learning rate of group 0 to 1.9531e-06.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "29  1400.0  98.454082  99.050206   0.074677   0.031728          -0.000443   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "29         0.045113  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "30  1450.0  98.218232  99.047309   0.078053   0.032368          -0.000485   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "30         0.044404  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "31  1500.0  98.844707   99.01765   0.049746   0.029228          -0.000564   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "31         0.046787  \n",
      "Epoch 00031: reducing learning rate of group 0 to 9.7656e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "32  1550.0  98.747051  98.971355   0.051394   0.033824          -0.000377   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "32         0.038141  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "33  1600.0  98.140848  99.137008   0.080794    0.02444          -0.000432   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "33         0.039435  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "34  1650.0  98.747051  99.061054   0.047979   0.029841          -0.000494   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "34         0.041783  \n",
      "Epoch 00034: reducing learning rate of group 0 to 4.8828e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "35  1700.0  98.669666  99.205005   0.047697   0.025056           -0.00037   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "35         0.035467  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "36  1750.0  98.885244  99.194157   0.053421   0.027298          -0.000368   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "36         0.034902  \n",
      "Epoch 00036: reducing learning rate of group 0 to 2.5000e-04.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "37  1800.0  99.178213  99.137008   0.032584   0.027619          -0.000274   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "37         0.027303  \n",
      "Epoch 00037: reducing learning rate of group 0 to 2.4414e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "38  1850.0  98.767322  99.115306   0.050859   0.026309          -0.000252   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "38         0.025968  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "39  1900.0  99.178213  99.147862     0.0373   0.024888          -0.000245   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "39         0.025672  \n",
      "Epoch 00039: reducing learning rate of group 0 to 1.2500e-04.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "40  1950.0  99.080557  99.169564   0.038161   0.024459           -0.00021   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "40         0.024562  \n",
      "Epoch 00040: reducing learning rate of group 0 to 1.2207e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "41  2000.0  99.178213   99.19126   0.030689   0.025391          -0.000193   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "41         0.022353  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "42  2050.0  99.178213   99.19126   0.032431   0.024073          -0.000163   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "42         0.020982  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "43  2100.0    98.9829  99.245518   0.041801   0.022881          -0.000202   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "43         0.020128  \n",
      "Epoch 00043: reducing learning rate of group 0 to 6.1035e-08.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "44  2150.0  99.275869   99.26722   0.031077   0.024339          -0.000216   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "44         0.019914  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "45  2200.0  99.080557  99.223816   0.039778   0.023398          -0.000148   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "45         0.019048  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "46  2250.0  99.178213  99.180412   0.033988   0.024438          -0.000176   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "46         0.018644  \n",
      "Epoch 00046: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch 00046: reducing learning rate of group 0 to 3.0518e-08.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "47  2300.0  99.275869  99.169564   0.032542   0.024522          -0.000142   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "47         0.018235  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "48  2350.0  99.080557  99.169564    0.03607   0.024436          -0.000134   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "48         0.017419  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "49  2400.0  99.275869  99.226707   0.034845    0.02256          -0.000124   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "49         0.016662  \n",
      "Epoch 00049: reducing learning rate of group 0 to 1.5259e-08.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "50  2450.0  99.080557  99.169564   0.038476   0.023405          -0.000139   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "50         0.016416  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "51  2500.0  99.080557  99.180412    0.04142   0.023468          -0.000144   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "51         0.016221  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "52  2550.0  99.275869  99.205005   0.035584    0.02348           -0.00012   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "52         0.015825  \n",
      "Epoch 00052: reducing learning rate of group 0 to 3.1250e-05.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "53  2600.0  99.080557  99.226707   0.041063   0.023432          -0.000119   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "53         0.016156  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "54  2650.0    98.9829  99.226707   0.041657    0.02299          -0.000127   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "54         0.014916  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "55  2700.0  99.275869  99.226707   0.036916   0.023788          -0.000111   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "55         0.014901  \n",
      "Epoch 00055: reducing learning rate of group 0 to 1.5625e-05.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "56  2750.0  99.080557  99.237561   0.041731   0.022944          -0.000095   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "56          0.01464  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "57  2800.0  99.080557  99.223816   0.037505   0.023021          -0.000091   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "57         0.014382  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "58  2850.0  99.178213  99.202114   0.037761   0.023359          -0.000098   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "58         0.014267  \n",
      "Epoch 00058: reducing learning rate of group 0 to 7.8125e-06.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "59  2900.0  99.275869  99.270111   0.037156   0.023434          -0.000105   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "59          0.01431  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "60  2950.0  99.178213  99.226707   0.038002   0.023567          -0.000078   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "60          0.01324  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "61  3000.0  99.080557  99.248409   0.038108   0.023374          -0.000067   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "61         0.013903  \n",
      "Epoch 00061: reducing learning rate of group 0 to 3.9063e-06.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "62  3050.0  99.275869  99.248409   0.036297   0.023437          -0.000084   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "62         0.013639  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "63  3100.0  99.275869  99.237561    0.03645   0.023476          -0.000065   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "63         0.012987  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "64  3150.0  99.275869  99.259257   0.036715   0.023144          -0.000084   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "64         0.013373  \n",
      "Epoch 00064: reducing learning rate of group 0 to 1.9531e-06.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "65  3200.0  99.275869  99.237561   0.037184   0.023195           -0.00007   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "65         0.012886  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "66  3250.0  99.275869  99.248409   0.036535   0.023039          -0.000074   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "66         0.012784  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "67  3300.0  99.275869  99.259257   0.036801   0.023218          -0.000077   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "67         0.012363  \n",
      "Epoch 00067: reducing learning rate of group 0 to 9.7656e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "68  3350.0  99.275869  99.226707   0.036031   0.023347          -0.000065   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "68         0.012636  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "69  3400.0  99.275869  99.248409   0.036427   0.023394          -0.000062   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "69         0.012341  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "70  3450.0  99.275869  99.248409   0.036602   0.023288          -0.000068   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "70         0.012679  \n",
      "Epoch 00070: reducing learning rate of group 0 to 4.8828e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "71  3500.0  99.275869  99.237561   0.036924   0.023329           -0.00006   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "71         0.012356  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "72  3550.0  99.275869  99.248409    0.03691   0.023227          -0.000063   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "72         0.012871  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "73  3600.0  99.275869  99.248409   0.036942   0.023222          -0.000063   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "73         0.012043  \n",
      "Epoch 00073: reducing learning rate of group 0 to 2.4414e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "74  3650.0  99.275869  99.248409   0.036914   0.023243          -0.000063   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "74         0.012629  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "75  3700.0  99.275869  99.237561   0.036717   0.023237          -0.000058   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "75          0.01258  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "76  3750.0  99.275869  99.248409   0.036599   0.023265          -0.000053   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "76         0.012519  \n",
      "Epoch 00076: reducing learning rate of group 0 to 1.2207e-07.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "77  3800.0  99.275869  99.248409   0.036796   0.023301          -0.000059   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "77         0.012622  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "78  3850.0  99.275869  99.248409   0.036871    0.02327          -0.000062   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "78         0.012262  \n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "79  3900.0  99.275869  99.248409   0.036799   0.023264          -0.000061   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "79         0.012714  \n",
      "Epoch 00079: reducing learning rate of group 0 to 6.1035e-08.\n",
      "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
      "80  3950.0  99.275869  99.248409   0.036629   0.023281          -0.000059   \n",
      "\n",
      "    MeanStudentLoss  \n",
      "80         0.012372  \n"
     ]
    }
   ],
   "source": [
    "history_forget = [evaluate(student, forget_valid_dl, device = device)]\n",
    "AccForget = history_forget[0][\"Acc\"]*100\n",
    "ErrForget = history_forget[0][\"Loss\"]\n",
    "\n",
    "history_retain = [evaluate(student, retain_valid_dl, device = device)]\n",
    "AccRetain = history_retain[0][\"Acc\"]*100\n",
    "ErrRetain = history_retain[0][\"Loss\"]\n",
    "\n",
    "df = pd.DataFrame(columns = [\"Epochs\", \"AccForget\", \"AccRetain\", \"ErrForget\", \"ErrRetain\", \"MeanGeneratorLoss\", \"MeanStudentLoss\"])\n",
    "df = df._append({\"Epochs\":0, \"AccForget\":AccForget, \"AccRetain\":AccRetain, \"ErrForget\":ErrForget,\n",
    "                \"ErrRetain\":ErrRetain, \"MeanGeneratorLoss\":None, \"MeanStudentLoss\":None}, ignore_index = True)\n",
    "\n",
    "# saving the generator\n",
    "torch.save(generator.state_dict(), os.path.join(generator_path, str(0) + \".pt\"))\n",
    "\n",
    "# saving the student\n",
    "torch.save(student.state_dict(), os.path.join(student_path, str(0) + \".pt\"))\n",
    "\n",
    "while n_pseudo_batches < total_n_pseudo_batches:\n",
    "    x_pseudo = generator.__next__()\n",
    "    preds, *_ = model(x_pseudo)\n",
    "\n",
    "    # Threshold Criteria\n",
    "    mask = (torch.softmax(preds.detach(), dim=1)[:, 0] <= threshold)\n",
    "\n",
    "    # Entropy Criteria\n",
    "    ENTROPY_THRESH = 0.25\n",
    "    for ix, p in enumerate(preds):\n",
    "      if get_entropy(p) > ENTROPY_THRESH:\n",
    "        mask[ix] = False\n",
    "\n",
    "    x_pseudo = x_pseudo[mask]\n",
    "    if x_pseudo.size(0) == 0:\n",
    "        zero_count += 1\n",
    "        if zero_count > 100:\n",
    "            print(\"Generator Stopped Producing datapoints corresponding to retain classes.\")\n",
    "            print(\"Resetting the generator to previous checkpoint\")\n",
    "            generator.load_state_dict(torch.load(os.path.join(generator_path, str(((n_pseudo_batches//50)-1)*50) + \".pt\")))\n",
    "        continue\n",
    "    else:\n",
    "        zero_count = 0\n",
    "\n",
    "    ## Take n_generator_iter steps on generator\n",
    "    if idx_pseudo % n_repeat_batch < n_generator_iter:\n",
    "        student_logits, *student_activations = student(x_pseudo)\n",
    "        teacher_logits, *teacher_activations = model(x_pseudo)\n",
    "        generator_total_loss = KT_loss_generator(student_logits, teacher_logits, KL_temperature=KL_temperature)\n",
    "\n",
    "        optimizer_generator.zero_grad()\n",
    "        generator_total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(generator.parameters(), 5)\n",
    "        optimizer_generator.step()\n",
    "        running_gen_loss.append(generator_total_loss.cpu().detach())\n",
    "\n",
    "\n",
    "    elif idx_pseudo % n_repeat_batch < (n_generator_iter + n_student_iter):\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_logits, *teacher_activations = model(x_pseudo)\n",
    "\n",
    "        student_logits, *student_activations = student(x_pseudo)\n",
    "        student_total_loss = KT_loss_student(student_logits, student_activations,\n",
    "                                             teacher_logits, teacher_activations,\n",
    "                                             KL_temperature=KL_temperature, AT_beta = AT_beta)\n",
    "\n",
    "        optimizer_student.zero_grad()\n",
    "        student_total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(student.parameters(), 5)\n",
    "        optimizer_student.step()\n",
    "        running_stu_loss.append(student_total_loss.cpu().detach())\n",
    "\n",
    "    if (idx_pseudo + 1) % n_repeat_batch == 0:\n",
    "        if((n_pseudo_batches)% 50 == 0):\n",
    "            MeanGLoss = np.mean(running_gen_loss)\n",
    "            running_gen_loss = []\n",
    "            MeanSLoss = np.mean(running_stu_loss)\n",
    "            running_stu_loss = []\n",
    "\n",
    "            history_forget = [evaluate(student, forget_valid_dl, device = device)]\n",
    "            AccForget = history_forget[0][\"Acc\"]*100\n",
    "            ErrForget = history_forget[0][\"Loss\"]\n",
    "\n",
    "            history_retain = [evaluate(student, retain_valid_dl, device = device)]\n",
    "            AccRetain = history_retain[0][\"Acc\"]*100\n",
    "            ErrRetain = history_retain[0][\"Loss\"]\n",
    "\n",
    "            df = df._append({\"Epochs\":n_pseudo_batches, \"AccForget\":AccForget, \"AccRetain\":AccRetain, \"ErrForget\":ErrForget,\n",
    "                            \"ErrRetain\":ErrRetain, \"MeanGeneratorLoss\":MeanGLoss, \"MeanStudentLoss\":MeanSLoss}, ignore_index = True)\n",
    "            print(df.iloc[-1:])\n",
    "            scheduler_student.step(history_retain[0][\"Loss\"])\n",
    "            scheduler_generator.step(history[0][\"Loss\"])\n",
    "\n",
    "            # saving the generator\n",
    "            torch.save(generator.state_dict(), os.path.join(generator_path, str(n_pseudo_batches) + \".pt\"))\n",
    "\n",
    "            # saving the student\n",
    "            torch.save(student.state_dict(), os.path.join(student_path, str(n_pseudo_batches) + \".pt\"))\n",
    "\n",
    "\n",
    "        n_pseudo_batches += 1\n",
    "\n",
    "    idx_pseudo += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0225e5d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T21:29:53.161201Z",
     "iopub.status.busy": "2024-04-12T21:29:53.160855Z",
     "iopub.status.idle": "2024-04-12T21:29:53.181045Z",
     "shell.execute_reply": "2024-04-12T21:29:53.180085Z"
    },
    "id": "sAf-ZaYDEiLI",
    "papermill": {
     "duration": 0.043275,
     "end_time": "2024-04-12T21:29:53.183119",
     "exception": false,
     "start_time": "2024-04-12T21:29:53.139844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epochs</th>\n",
       "      <th>AccForget</th>\n",
       "      <th>AccRetain</th>\n",
       "      <th>ErrForget</th>\n",
       "      <th>ErrRetain</th>\n",
       "      <th>MeanGeneratorLoss</th>\n",
       "      <th>MeanStudentLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>450.0</td>\n",
       "      <td>85.545033</td>\n",
       "      <td>75.776184</td>\n",
       "      <td>0.772520</td>\n",
       "      <td>0.689638</td>\n",
       "      <td>-0.001833</td>\n",
       "      <td>0.106669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500.0</td>\n",
       "      <td>92.233562</td>\n",
       "      <td>83.798468</td>\n",
       "      <td>0.492956</td>\n",
       "      <td>0.472704</td>\n",
       "      <td>-0.001328</td>\n",
       "      <td>0.092433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>550.0</td>\n",
       "      <td>89.182270</td>\n",
       "      <td>85.361695</td>\n",
       "      <td>0.529845</td>\n",
       "      <td>0.387618</td>\n",
       "      <td>-0.000945</td>\n",
       "      <td>0.090699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>600.0</td>\n",
       "      <td>97.201133</td>\n",
       "      <td>85.693002</td>\n",
       "      <td>0.215013</td>\n",
       "      <td>0.350229</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>0.102793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>650.0</td>\n",
       "      <td>92.408609</td>\n",
       "      <td>94.866902</td>\n",
       "      <td>0.387700</td>\n",
       "      <td>0.175202</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>0.092109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>700.0</td>\n",
       "      <td>93.641287</td>\n",
       "      <td>97.427666</td>\n",
       "      <td>0.400890</td>\n",
       "      <td>0.115978</td>\n",
       "      <td>-0.000825</td>\n",
       "      <td>0.085356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>750.0</td>\n",
       "      <td>98.140848</td>\n",
       "      <td>98.634982</td>\n",
       "      <td>0.180643</td>\n",
       "      <td>0.053242</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>0.081713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>800.0</td>\n",
       "      <td>95.106131</td>\n",
       "      <td>98.431712</td>\n",
       "      <td>0.276824</td>\n",
       "      <td>0.068320</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>0.085407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>850.0</td>\n",
       "      <td>96.045840</td>\n",
       "      <td>98.512733</td>\n",
       "      <td>0.225446</td>\n",
       "      <td>0.057395</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>0.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>900.0</td>\n",
       "      <td>96.672320</td>\n",
       "      <td>98.718899</td>\n",
       "      <td>0.183967</td>\n",
       "      <td>0.042214</td>\n",
       "      <td>-0.000734</td>\n",
       "      <td>0.068694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epochs  AccForget  AccRetain  ErrForget  ErrRetain  MeanGeneratorLoss  \\\n",
       "10   450.0  85.545033  75.776184   0.772520   0.689638          -0.001833   \n",
       "11   500.0  92.233562  83.798468   0.492956   0.472704          -0.001328   \n",
       "12   550.0  89.182270  85.361695   0.529845   0.387618          -0.000945   \n",
       "13   600.0  97.201133  85.693002   0.215013   0.350229          -0.001336   \n",
       "14   650.0  92.408609  94.866902   0.387700   0.175202          -0.000959   \n",
       "15   700.0  93.641287  97.427666   0.400890   0.115978          -0.000825   \n",
       "16   750.0  98.140848  98.634982   0.180643   0.053242          -0.000877   \n",
       "17   800.0  95.106131  98.431712   0.276824   0.068320          -0.001005   \n",
       "18   850.0  96.045840  98.512733   0.225446   0.057395          -0.000656   \n",
       "19   900.0  96.672320  98.718899   0.183967   0.042214          -0.000734   \n",
       "\n",
       "    MeanStudentLoss  \n",
       "10         0.106669  \n",
       "11         0.092433  \n",
       "12         0.090699  \n",
       "13         0.102793  \n",
       "14         0.092109  \n",
       "15         0.085356  \n",
       "16         0.081713  \n",
       "17         0.085407  \n",
       "18         0.069800  \n",
       "19         0.068694  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "008e3803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T21:29:53.226385Z",
     "iopub.status.busy": "2024-04-12T21:29:53.226087Z",
     "iopub.status.idle": "2024-04-12T21:29:53.234895Z",
     "shell.execute_reply": "2024-04-12T21:29:53.234203Z"
    },
    "id": "0SVUfjiWEitM",
    "papermill": {
     "duration": 0.032566,
     "end_time": "2024-04-12T21:29:53.236824",
     "exception": false,
     "start_time": "2024-04-12T21:29:53.204258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"MNIST_ALLCNN.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21254cc8",
   "metadata": {
    "id": "VdoxXEA3V10E",
    "papermill": {
     "duration": 0.020201,
     "end_time": "2024-04-12T21:29:53.277053",
     "exception": false,
     "start_time": "2024-04-12T21:29:53.256852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10400.506353,
   "end_time": "2024-04-12T21:29:56.166664",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-12T18:36:35.660311",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
